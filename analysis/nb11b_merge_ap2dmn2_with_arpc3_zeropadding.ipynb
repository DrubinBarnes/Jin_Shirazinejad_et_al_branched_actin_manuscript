{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cyna Shirazinejad, 7/7/21\n",
    "\n",
    "# Notebook 11b: merge AP2 with ARPC3, 'zero' padding\n",
    "\n",
    "outline:\n",
    "* find ARPC3+/- events\n",
    "* measure the effect of CCP motility with ARPC3 recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import all necessary Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "unique_user_path_notebook = str(np.load('unique_user_path_notebook.npy'))\n",
    "unique_user_saved_outputs = str(np.load('unique_user_saved_outputs.npy'))\n",
    "unique_user_saved_tracks = str(np.load('unique_user_path_tracks.npy'))\n",
    "sys.path.append(unique_user_path_notebook+'/cmeAnalysisPostProcessingPythonScripts') # add custom Python scripts to the local path\n",
    "import merge_tools\n",
    "import generate_index_dictionary\n",
    "import return_track_attributes\n",
    "index_dictionary = generate_index_dictionary.return_index_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframe from notebook 3 containing normal-pdf scaled features: PC's and GMM predicted clusters, and dataframe with cmeAnalysis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcs_normal_scaled_with_gmm_cluster = pd.read_csv(unique_user_saved_outputs+'/dataframes/df_new_incorporated_data_pcs_gmm_clusters.zip')\n",
    "df_merged_features = pd.read_csv(unique_user_saved_outputs+'/dataframes/df_new_incorporated_data_merged_features.zip')\n",
    "index_dnm2positive = np.load(unique_user_saved_outputs+'/dataframes/cluster_dnm2_positive.npy')\n",
    "number_of_track_splits = np.load(unique_user_saved_outputs+'/dataframes/number_of_track_splits.npy')\n",
    "number_of_clusters = np.load(unique_user_saved_outputs+\"/dataframes/number_of_clusters.npy\")\n",
    "ccp_predictions = np.load(unique_user_saved_outputs+'/dataframes/merged_ccp_predictions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_peak_params = np.load(unique_user_saved_outputs+'/dataframes/parameters_best_fit_peak_finding.npy')\n",
    "sos = signal.butter(4, 0.2, 'lp', fs=1, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all valid arpc3 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tracks_arpc3 = [np.load(unique_user_saved_outputs+'/dataframes/valid_arpc3_tracks_0.npy', allow_pickle=True)]\n",
    "\n",
    "for i in range(1, 13):\n",
    "    valid_tracks_arpc3 += [np.load(unique_user_saved_outputs+'/dataframes/valid_arpc3_tracks_'+str(i)+'.npy', allow_pickle=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_tracks_arpc3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valid_tracks_arpc3 = merge_tools.merge_experiments(valid_tracks_arpc3,[list(range(len(track_set))) for track_set in valid_tracks_arpc3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all valid tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_valid_tracks = np.load(unique_user_saved_outputs+'/dataframes/all_experiments_merged_all_valid_tracks_0.npy', allow_pickle=True)\n",
    "\n",
    "for i in range(1, number_of_track_splits):\n",
    "\n",
    "    merged_all_valid_tracks = np.concatenate((merged_all_valid_tracks,\n",
    "                                              np.load(unique_user_saved_outputs+'/dataframes/all_experiments_merged_all_valid_tracks_'+str(i)+'.npy', allow_pickle=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_valid_tracks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort DNM2+ events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gmm_clusters = number_of_clusters # optimal number of clusters of PCA data\n",
    "\n",
    "\n",
    "gmm_classes = []\n",
    "\n",
    "for i in range(num_gmm_clusters):\n",
    "\n",
    "    gmm_classes.append(df_pcs_normal_scaled_with_gmm_cluster[df_pcs_normal_scaled_with_gmm_cluster['gmm_predictions']==i].index.values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gmm_classes[index_dnm2positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_authentic_ccps_gmm = merged_all_valid_tracks[gmm_classes[index_dnm2positive]] #dnm2 positive events, mixed CCPS and hot-spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tracks_authentic_ccps_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isolate hot-spot and individual CCP mixed authentic CCP class from gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number_track_candidates = df_merged_features['experiment_number'][gmm_classes[index_dnm2positive]] # experiment numbers (1-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(experiment_number_track_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate single-CCP events by experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_valid_tracks_per_experiment = [] # each entry is a list for each experiment of tracks corresponding to predicted ccps \n",
    "hotspot_events_per_experiment = [] # each entry is a list for each experiment of tracks corresponding to predicted hot-spots \n",
    "ccp_events_per_experiment = []\n",
    "\n",
    "for experiment_number in range(8, 21): # only look at 3-color movies\n",
    "    \n",
    "    current_exp_ind = np.where(experiment_number_track_candidates==experiment_number)[0] # all events in current experiment\n",
    "    hotspot_pred_exp = ccp_predictions[current_exp_ind] # hot-spot predictions for current experiment\n",
    "    tracks_exp = tracks_authentic_ccps_gmm[current_exp_ind] # all tracks in current experiment\n",
    "    \n",
    "    non_hotspot_ind = np.where(hotspot_pred_exp==1)[0] # single ccp event indices\n",
    "    tracks_single_ccp_exp = tracks_exp[non_hotspot_ind] # single ccp tracks\n",
    "    ccp_events_per_experiment.append(tracks_single_ccp_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # measure ap2 initiation to dnm2 peak lifetime, comparing 2 cell lines -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all CCPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ccps = merge_tools.merge_experiments(ccp_events_per_experiment, [list(range(len(track_set))) for track_set in ccp_events_per_experiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_ccps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload (or load) trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpc3_trees = []\n",
    "\n",
    "for i in range(8,21):\n",
    "    \n",
    "    with open(unique_user_saved_outputs+'/dataframes/arpc3_kdtree_'+str(i), 'rb') as f:\n",
    "        tree = pickle.load(f)\n",
    "        \n",
    "    index_matrix = np.load(unique_user_saved_outputs+\"/dataframes/arpc3_tree_index_matrix_\"+str(i)+'.npy', allow_pickle=True)\n",
    "\n",
    "    arpc3_trees.append([tree, index_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_query = 2 # pixel search radius for associating ap2 and arpc3 from separate tracking\n",
    "\n",
    "# arpc3 positive events, padded in non-overlapping frames\n",
    "ch0_vectors_arpc3_positive = [] # amplitudes #\n",
    "ch1_vectors_arpc3_positive = [] #\n",
    "ch2_vectors_arpc3_positive = [] #\n",
    "channel_0_1_separations_arpc3_positive = [] # distance in microns between ap2 and dnm2\n",
    "channel_0_2_separations_arpc3_positive = [] # distance in microns between ap2 and arpc3\n",
    "channel_1_2_separations_arpc3_positive = []\n",
    "final_separations_ap2arpc3_arpc3_positive = [] # ap2 and arpc3 final separation in last overlapping frame of ap2 and arpc3\n",
    "initial_separations_ap2arpc3_arpc3_positive = [] # ap2 and arpc3 initial separation in first overlapping frame of ap2 and arpc3\n",
    "ap2_arpc3_separation_at_dnm2_peak_arpc3_positive = [] # ap2 and arpc3 separation at peak of dnm2 signal\n",
    "ap2_arpc3_separation_at_arpc3_peak_arpc3_positive = []\n",
    "ap2_arpc3_separation_at_ap2_peak_arpc3_positive = []\n",
    "ap2_lifetime_arpc3_positive = [] # ap2 lifetime\n",
    "arpc3_lifetime_arpc3_positive = []\n",
    "max_separation_ap2_arpc3_arpc3_positive = [] # maximum separation between ap2 and arpc3\n",
    "max_separation_ap2_dnm2_arpc3_positive = []\n",
    "max_separation_dnm2_arpc3_arpc3_positive = []\n",
    "num_frames_associated_arpc3_positive = [] # number of frames shared between ap2 and arpc3 in movie that are below the query radius in KDTree search\n",
    "time_ap2_appearance_to_dnm2_peak_arpc3_positive = []\n",
    "maximum_ap2_intensity_arpc3_positive = []\n",
    "maximum_dnm2_intensity_arpc3_positive = []\n",
    "maximum_arpc3_intensity_arpc3_positive = []\n",
    "pval_arpc3_ccps_arpc3_positive = []\n",
    "time_arpc3_appearance_to_dnm2_peak_arpc3_positive = []\n",
    "fraction_arpc3_positive = []\n",
    "ccps_arpc3_positive = []\n",
    "average_ap2_movement_before_dnm2_peak_arpc3_positive = []\n",
    "average_ap2_movement_after_dnm2_peak_arpc3_positive = []\n",
    "\n",
    "ap2_arpc3_separation_average_arpc3_positive = []\n",
    "experiment_number_arpc3_positive = []\n",
    "dnm2_arpc3_peak_time_difference_arpc3_positive = []\n",
    "\n",
    "\n",
    "# arpc3 negative events\n",
    "ch0_vectors_arpc3_negative = []\n",
    "ch1_vectors_arpc3_negative = []\n",
    "channel_0_1_separations_arpc3_negative = []\n",
    "ccps_arpc3_negative = []\n",
    "time_ap2_appearance_to_dnm2_peak_arpc3_negative = []\n",
    "ap2_lifetime_arpc3_negative = []\n",
    "experiment_number_arpc3_negative = []\n",
    "average_ap2_movement_before_dnm2_peak_arpc3_negative = []\n",
    "average_ap2_movement_after_dnm2_peak_arpc3_negative = []\n",
    "\n",
    "arcp3_phenotypes_split_empty_early_late = []\n",
    "\n",
    "num_frames_associated = []\n",
    "\n",
    "absolute_ap2_x_position_arpc3_positive = []\n",
    "absolute_ap2_y_position_arpc3_positive = []\n",
    "\n",
    "significant_arpc3_at_dnm2_peak_arpc3_positive = []\n",
    "\n",
    "num_no_neighbors = 0\n",
    "\n",
    "for experiment_number in range(8,21):  # iterate over all experiments\n",
    "\n",
    "    num_early = 0\n",
    "    num_late = 0\n",
    "    \n",
    "    num_with_mode = 0 # count number of events with and without arpc3\n",
    "    num_without_mode = 0    \n",
    "    num_no_neighbors=0\n",
    "    print('current experiment number: ' + str(experiment_number))\n",
    "    ap2dmn2_tracks_in_experiment = ccp_events_per_experiment[experiment_number-8] # filtered tracks\n",
    "    print('number of ap2 tracks: ' + str(len(ap2dmn2_tracks_in_experiment)))\n",
    "    arpc3_experiment=valid_tracks_arpc3[experiment_number-8] # cat 1 and 2 arpc3 events in experiment\n",
    "    print('number of arpc3 tracks: ' + str(len(arpc3_experiment)))\n",
    "\n",
    "    \n",
    "    # select a tree for each frame containing all events in each frame\n",
    "    kd_tree_arpc3_experiment, vals_tree = arpc3_trees[experiment_number-8]\n",
    "    \n",
    "    print('iterating through tracks in experiment')\n",
    "    \n",
    "    for track_num in range(len(ap2dmn2_tracks_in_experiment)): # iterate through all ap2 tracks in experiment\n",
    "\n",
    "        \n",
    "        frames_in_track_first_channel = list(return_track_attributes.return_frames_in_track_no_buffer(ap2dmn2_tracks_in_experiment, track_num)-1) # frames of ap2 and dnm2\n",
    "        ch0_x = return_track_attributes.return_puncta_x_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 0) # positions of ap2 and dnm2\n",
    "        ch0_y = return_track_attributes.return_puncta_y_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 0)\n",
    "        ch1_x = return_track_attributes.return_puncta_x_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 1)\n",
    "        ch1_y = return_track_attributes.return_puncta_y_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 1)\n",
    "        ap2_int = return_track_attributes.return_track_amplitude_no_buffer_channel(ap2dmn2_tracks_in_experiment, track_num, 0) # ap2 and dnm2 intensities\n",
    "        dnm2_int = return_track_attributes.return_track_amplitude_no_buffer_channel(ap2dmn2_tracks_in_experiment, track_num, 1)\n",
    "        \n",
    "        filtered_dnm2_signal = list(list(signal.sosfilt(sos, dnm2_int)) + [0, 0, 0, 0, 0])\n",
    "    \n",
    "        dnm2_peak = signal.find_peaks(filtered_dnm2_signal, \n",
    "                                      distance=best_fit_peak_params[0], \n",
    "                                      height=best_fit_peak_params[1],\n",
    "                                      width=best_fit_peak_params[2])[0][0]\n",
    "        \n",
    "        frame_dnm2_peak = frames_in_track_first_channel[dnm2_peak] # the movie frame (indexed starting from 0) that dnm2 peaks     \n",
    "        candidate_arpc3_neighbors = [] # indices of arpc3 events that take place near ap2\n",
    "        no_neighbors=True # no neighbors found yet\n",
    "        \n",
    "        # search for candidate arpc3 neighbors in each ap2 track's frame\n",
    "        for frame in frames_in_track_first_channel:\n",
    "            \n",
    "            frame_ch0 = frames_in_track_first_channel.index(frame)\n",
    "            # frame's tree\n",
    "            current_tree = kd_tree_arpc3_experiment[frame]\n",
    "            \n",
    "            # ap2 fitted position at current frame\n",
    "            current_ap2_position = np.array([ch0_x[frame_ch0], ch0_y[frame_ch0]]).reshape(1, -1)\n",
    "            \n",
    "            # indices of arpc3 events within the query radius\n",
    "            ind = current_tree.query_radius(current_ap2_position,\n",
    "                                            r=distance_query)\n",
    "\n",
    "            if len(ind[0])>0:\n",
    "                no_neighbors = False # if there is a neighbor\n",
    "                \n",
    "            # check if each arpc3 neighbor originated before or after the ap2 event\n",
    "            for candidate in ind[0]:\n",
    "\n",
    "                candidate_index = int(vals_tree[frame][candidate][0]) # get the index of the arpc3 event\n",
    "                \n",
    "                frames_in_track_candidate_neighbor = list(return_track_attributes.return_frames_in_track_no_buffer(arpc3_experiment, candidate_index)-1)\n",
    "                \n",
    "                # consider the arpc3 event if it originated after the ap2 event and before the dnm2 peak\n",
    "                if frames_in_track_candidate_neighbor[0]>frames_in_track_first_channel[0] and frames_in_track_candidate_neighbor[0]<frame_dnm2_peak:\n",
    "\n",
    "                    candidate_arpc3_neighbors.append(candidate_index)\n",
    "        \n",
    "            \n",
    "        if no_neighbors==True: # if there are absolutely no neighbors present, the CCP is arpc3 negative\n",
    "            \n",
    "            num_no_neighbors+=1\n",
    "            \n",
    "        # get mode(s) of candidates\n",
    "        mode=stats.mode(candidate_arpc3_neighbors)\n",
    "        \n",
    "        # if there is a unique candidate:\n",
    "        if mode[0].size == 1:\n",
    "\n",
    "            num_frames_associated.append(mode[1][0])\n",
    "            \n",
    "            num_with_mode+=1 # count this track as arpc3 positive\n",
    "\n",
    "            pval_arpc3_detection = []\n",
    "            \n",
    "        \n",
    "            associated_track_second_channel = mode[0][0] # index of arpc3 track associated with current ap2 track\n",
    "            \n",
    "            frames_in_track_second_channel = list(return_track_attributes.return_frames_in_track_no_buffer(arpc3_experiment, associated_track_second_channel)-1) # frames of arpc3 track\n",
    "            \n",
    "            frames_intersection = list(set(frames_in_track_first_channel) & set(frames_in_track_second_channel)) # find all frames ap2 and arpc3 overlap during movie\n",
    "            frames_intersection.sort() # sort the frames in ascending order\n",
    "\n",
    "            # amplitudes of all channels\n",
    "            ch0_amplitudes = ap2_int # ap2, dnm2, arpc3 intensities\n",
    "            ch1_amplitudes = dnm2_int\n",
    "            ch2_amplitudes = return_track_attributes.return_track_amplitude_no_buffer_channel(arpc3_experiment, associated_track_second_channel, 0)\n",
    "\n",
    "            # position of arpc3\n",
    "            ch2_x = return_track_attributes.return_puncta_x_position_no_buffer_one_channel(arpc3_experiment, associated_track_second_channel, 0)\n",
    "            ch2_y = return_track_attributes.return_puncta_y_position_no_buffer_one_channel(arpc3_experiment, associated_track_second_channel, 0)\n",
    "\n",
    "            # correct intensities and positions for missing frames where ap2 and arpc3 are non-overlapping\n",
    "            new_ch0_vector = []\n",
    "            new_ch1_vector = []\n",
    "            new_ch2_vector = []\n",
    "            new_ch0_x = []\n",
    "            new_ch0_y = []\n",
    "            new_ch1_x = []\n",
    "            new_ch1_y = []\n",
    "            new_ch2_x = []\n",
    "            new_ch2_y = []\n",
    "            \n",
    "            # first/last frame either ap2 or arpc3 shows up\n",
    "            min_frame = np.nanmin([np.nanmin(frames_in_track_first_channel),np.nanmin(frames_in_track_second_channel)]) #nan to account for gaps\n",
    "            max_frame = np.nanmax([np.nanmax(frames_in_track_first_channel),np.nanmax(frames_in_track_second_channel)])\n",
    "\n",
    "            # all frames shared between ap2 and arpc3\n",
    "            frames_all = [i for i in range(int(min_frame),int(max_frame)+1)]\n",
    "\n",
    "            channel_0_2_separation_track = [] # ap2 and arpc3 separation\n",
    "            channel_0_2_angle_track = [] # ap2 and arpc3 angle \n",
    "            channel_0_1_separation_track = [] # ap2 and dnm2 separation\n",
    "            channel_1_2_separation_track = []\n",
    "\n",
    "            for frame in frames_all: # iterate over all frames\n",
    "\n",
    "                # if frames of ap2 and arpc3 are non-overlapping, do not measure their separation\n",
    "                if (frame in frames_in_track_first_channel and frame not in frames_in_track_second_channel) or (frame in frames_in_track_second_channel and frame not in frames_in_track_first_channel):\n",
    "                    channel_0_2_separation_track.append(0)\n",
    "                    channel_0_2_angle_track.append(0)\n",
    "                    channel_1_2_separation_track.append(0)\n",
    "                # if only ap2 is present\n",
    "                if frame in frames_in_track_first_channel and frame not in frames_in_track_second_channel:\n",
    "                    \n",
    "                    channel_0_index = frames_in_track_first_channel.index(frame) # get relative index of ap2 in this frame \n",
    "\n",
    "                    new_ch0_vector.append(ch0_amplitudes[channel_0_index]) # add ap2 and dnm2 amplitudes\n",
    "                    new_ch1_vector.append(ch1_amplitudes[channel_0_index]) \n",
    "                    new_ch0_x.append(ch0_x[channel_0_index]) # ap2 and dnm2 positions\n",
    "                    new_ch0_y.append(ch0_y[channel_0_index])\n",
    "                    new_ch1_x.append(ch1_x[channel_0_index])\n",
    "                    new_ch1_y.append(ch1_y[channel_0_index])\n",
    "\n",
    "                    new_ch2_vector.append(0) # no arpc3\n",
    "                    new_ch2_x.append(0) # arpc3 position off grid\n",
    "                    new_ch2_y.append(0)\n",
    "                    pval_arpc3_detection.append(np.NaN)\n",
    "                    \n",
    "                    channel_0_1_separation_track.append(np.sqrt((0.108*(ch0_x[channel_0_index]-ch1_x[channel_0_index]))**2 + (0.108*(ch0_y[channel_0_index]-ch1_y[channel_0_index]))**2)) # ap2-dnm2 separation\n",
    "\n",
    "                # if only arpc3 is present\n",
    "                elif frame in frames_in_track_second_channel and frame not in frames_in_track_first_channel: \n",
    "\n",
    "                    channel_2_index = frames_in_track_second_channel.index(frame) # get relative index of arpc3 in this frame \n",
    "\n",
    "                    new_ch2_vector.append(ch2_amplitudes[channel_2_index]) # add arpc3 amplitudes and positions\n",
    "                    new_ch2_x.append(ch2_x[channel_2_index]) \n",
    "                    new_ch2_y.append(ch2_y[channel_2_index])\n",
    "                    \n",
    "                    new_ch0_vector.append(0) # no ap2 or dnm2\n",
    "                    new_ch1_vector.append(0)    \n",
    "                    new_ch0_x.append(0) # ap2 and dnm2 position off grid\n",
    "                    new_ch0_y.append(0)\n",
    "                    new_ch1_x.append(0)\n",
    "                    new_ch1_y.append(0)\n",
    "           \n",
    "                    channel_0_1_separation_track.append(0) # no separation between ap2 and dnm2 \n",
    "                    \n",
    "                    pval_arpc3_detection.append(return_track_attributes.return_pvals_detection_no_buffer(arpc3_experiment, associated_track_second_channel, 0)[channel_2_index])\n",
    "                \n",
    "                # if both ap2 and arpc3 in frame\n",
    "                elif frame in frames_in_track_first_channel and frame in frames_in_track_second_channel:  \n",
    "\n",
    "                    channel_0_index = frames_in_track_first_channel.index(frame) # get relative indices\n",
    "                    channel_2_index = frames_in_track_second_channel.index(frame)\n",
    "\n",
    "                    new_ch0_vector.append(ch0_amplitudes[channel_0_index]) # add amplitudes and positionsfor all channels\n",
    "                    new_ch1_vector.append(ch1_amplitudes[channel_0_index])\n",
    "                    new_ch2_vector.append(ch2_amplitudes[channel_2_index])\n",
    "                    new_ch0_x.append(ch0_x[channel_0_index]) # ap2 and dnm2 positions\n",
    "                    new_ch0_y.append(ch0_y[channel_0_index])\n",
    "                    new_ch1_x.append(ch1_x[channel_0_index])\n",
    "                    new_ch1_y.append(ch1_y[channel_0_index])\n",
    "                    new_ch2_x.append(ch2_x[channel_2_index]) \n",
    "                    new_ch2_y.append(ch2_y[channel_2_index])\n",
    "\n",
    "                    channel_0_1_separation_track.append(np.sqrt((0.108*(ch0_x[channel_0_index]-ch1_x[channel_0_index]))**2 + (0.108*(ch0_y[channel_0_index]-ch1_y[channel_0_index]))**2)) # ap2-dnm2 separation\n",
    "                    \n",
    "                    # ap2 and arpc3 separation\n",
    "                    channel_0_2_separation_track.append(np.sqrt((0.108*(ch0_x[channel_0_index]-ch2_x[channel_2_index]))**2 + (0.108*(ch0_y[channel_0_index]-ch2_y[channel_2_index]))**2))\n",
    "#                     channel_0_2_angle_track.append(angle_between((0,0),((ch0_x[channel_0_index]-ch2_x[channel_2_index]),(ch0_y[channel_0_index]-ch2_y[channel_2_index]))))              \n",
    "                    channel_1_2_separation_track.append(np.sqrt((0.108*(ch1_x[channel_0_index]-ch2_x[channel_2_index]))**2 + (0.108*(ch1_y[channel_0_index]-ch2_y[channel_2_index]))**2))\n",
    "\n",
    "                    pval_arpc3_detection.append(return_track_attributes.return_pvals_detection_no_buffer(arpc3_experiment,associated_track_second_channel,0)[channel_2_index])\n",
    " \n",
    "            filtered_dnm2_signal = list(list(signal.sosfilt(sos, dnm2_int)) + [0, 0, 0, 0, 0])\n",
    "    \n",
    "            dnm2_peak = signal.find_peaks(filtered_dnm2_signal, \n",
    "                                          distance=best_fit_peak_params[0], \n",
    "                                          height=best_fit_peak_params[1],\n",
    "                                          width=best_fit_peak_params[2])[0][0]\n",
    "        \n",
    "            if pval_arpc3_detection[dnm2_peak]<0.01 and pval_arpc3_detection[dnm2_peak]!=np.NaN:\n",
    "            \n",
    "                significant_arpc3_at_dnm2_peak_arpc3_positive.append(1)\n",
    "                num_late += 1\n",
    "                absolute_ap2_x_position_arpc3_positive.append(ch0_x)\n",
    "                absolute_ap2_y_position_arpc3_positive.append(ch0_y)\n",
    "            else:\n",
    "                \n",
    "                significant_arpc3_at_dnm2_peak_arpc3_positive.append(0)\n",
    "                num_early += 1\n",
    "                \n",
    "            ccps_arpc3_positive.append(ap2dmn2_tracks_in_experiment[track_num])\n",
    "            ap2_lifetime_arpc3_positive.append(len(frames_in_track_first_channel))\n",
    "            arpc3_lifetime_arpc3_positive.append(len(frames_in_track_second_channel))\n",
    "            # measure ap2 and arpc3 separation at dnm2 peak\n",
    "\n",
    "            ap2_arpc3_separation_at_dnm2_peak_arpc3_positive.append(channel_0_2_separation_track[dnm2_peak])\n",
    "            ap2_arpc3_separation_at_arpc3_peak_arpc3_positive.append(channel_0_2_separation_track[np.nanargmax(new_ch2_vector)])\n",
    "            ap2_arpc3_separation_at_ap2_peak_arpc3_positive.append(channel_0_2_separation_track[np.nanargmax(new_ch0_vector)])\n",
    "            ap2_arpc3_separation_average_arpc3_positive.append(np.nanmean(channel_0_2_separation_track))\n",
    "            # store measurements\n",
    "            ch0_vectors_arpc3_positive.append(new_ch0_vector)\n",
    "            ch1_vectors_arpc3_positive.append(new_ch1_vector)\n",
    "            ch2_vectors_arpc3_positive.append(new_ch2_vector)\n",
    "#             print(new_ch2_vector)\n",
    "            channel_0_2_separations_arpc3_positive.append(channel_0_2_separation_track)\n",
    "            channel_0_1_separations_arpc3_positive.append(channel_0_1_separation_track)  \n",
    "            channel_1_2_separations_arpc3_positive.append(channel_1_2_separation_track)  \n",
    "            channel_0_2_separation_track = np.array(channel_0_2_separation_track)\n",
    "            channel_0_1_separation_track = np.array(channel_0_1_separation_track)\n",
    "            channel_1_2_separation_track = np.array(channel_1_2_separation_track)\n",
    "            final_separations_ap2arpc3_arpc3_positive.append(channel_0_2_separation_track[~np.isnan(channel_0_2_separation_track)][-1])      \n",
    "            initial_separations_ap2arpc3_arpc3_positive.append(channel_0_2_separation_track[~np.isnan(channel_0_2_separation_track)][0])   \n",
    "            max_separation_ap2_arpc3_arpc3_positive.append(np.nanmax(channel_0_2_separation_track))\n",
    "            max_separation_ap2_dnm2_arpc3_positive.append(np.nanmax(channel_0_1_separation_track))\n",
    "            max_separation_dnm2_arpc3_arpc3_positive.append(np.nanmax(channel_1_2_separation_track))\n",
    "            num_frames_associated_arpc3_positive.append(mode[1][0])\n",
    "            pval_arpc3_ccps_arpc3_positive.append(pval_arpc3_detection)\n",
    "            maximum_ap2_intensity_arpc3_positive.append(np.nanmax(new_ch0_vector))\n",
    "            maximum_dnm2_intensity_arpc3_positive.append(np.nanmax(new_ch1_vector))\n",
    "            maximum_arpc3_intensity_arpc3_positive.append(np.nanmax(new_ch2_vector))      \n",
    "            time_ap2_appearance_to_dnm2_peak_arpc3_positive.append(dnm2_peak)\n",
    "            time_arpc3_appearance_to_dnm2_peak_arpc3_positive.append(int(frames_in_track_first_channel[dnm2_peak]) - int(frames_in_track_second_channel[0]))\n",
    "            experiment_number_arpc3_positive.append(experiment_number)\n",
    "            \n",
    "            dnm2_arpc3_peak_time_difference_arpc3_positive.append(np.nanargmax(ch1_amplitudes)-np.nanargmax(ch2_amplitudes))\n",
    "            \n",
    "            # concatenate all track positions and amplitudes\n",
    "            track_x_positions = [new_ch0_x, new_ch1_x, new_ch2_x]\n",
    "            track_y_positions = [new_ch0_y, new_ch1_y, new_ch2_y]\n",
    "            channel_intensity_vectors = [new_ch0_vector, new_ch1_vector, new_ch2_vector]   \n",
    "             \n",
    "            ap2_x_positions = new_ch0_x\n",
    "            ap2_y_positions = new_ch0_y     \n",
    "            \n",
    "            num_before=5\n",
    "            ap2movement = []\n",
    "            for dnm2_index in range(dnm2_peak-num_before,dnm2_peak):\n",
    "\n",
    "                try: \n",
    "                    \n",
    "                    if ap2_x_positions[dnm2_index] != 0 and ap2_x_positions[dnm2_index+1] != 0:\n",
    "                        \n",
    "                        ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "                        ap2movement.append(ap2temp)\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        ap2movement.append(np.NaN)\n",
    "\n",
    "                except Exception:\n",
    "\n",
    "                    ap2movement.append(np.NaN)\n",
    "\n",
    "            average_ap2_movement_before_dnm2_peak_arpc3_positive.append(np.nanmean(ap2movement))            \n",
    "\n",
    "            num_after=5\n",
    "            ap2movement = []\n",
    "            for dnm2_index in range(dnm2_peak,dnm2_peak+num_after):\n",
    "\n",
    "                try: \n",
    "                    \n",
    "                    if ap2_x_positions[dnm2_index] != 0 and ap2_x_positions[dnm2_index+1] != 0:\n",
    "                        \n",
    "                        ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "                        ap2movement.append(ap2temp)\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        ap2movement.append(np.NaN)\n",
    "\n",
    "                except Exception:\n",
    "\n",
    "                    ap2movement.append(np.NaN)\n",
    "\n",
    "            average_ap2_movement_after_dnm2_peak_arpc3_positive.append(np.nanmean(ap2movement)) \n",
    "            \n",
    "        elif no_neighbors==True: # if there is no mode then the event is arpc3 negative\n",
    "\n",
    "            num_without_mode += 1 \n",
    "            experiment_number_arpc3_negative.append(experiment_number)\n",
    "            ccps_arpc3_negative.append(ap2dmn2_tracks_in_experiment[track_num])\n",
    "            ap2_lifetime_arpc3_negative.append(len(ap2_int))\n",
    "\n",
    "            ch0_vectors_arpc3_negative.append(ap2_int)\n",
    "            ch1_vectors_arpc3_negative.append(dnm2_int)\n",
    "\n",
    "            filtered_dnm2_signal = list(list(signal.sosfilt(sos, dnm2_int)) + [0, 0, 0, 0, 0])\n",
    "    \n",
    "            dnm2_peak = signal.find_peaks(filtered_dnm2_signal, \n",
    "                                          distance=best_fit_peak_params[0], \n",
    "                                          height=best_fit_peak_params[1],\n",
    "                                          width=best_fit_peak_params[2])[0][0]\n",
    "            \n",
    "            time_ap2_appearance_to_dnm2_peak_arpc3_negative.append(dnm2_peak)\n",
    "            \n",
    "                        \n",
    "            channel_0_1_separation_track = []\n",
    "            \n",
    "            for frame in range(len(ch0_x)):\n",
    "                \n",
    "                channel_0_1_separation_track.append(np.sqrt((0.108*(ch0_x[frame]-ch1_x[frame]))**2 + (0.108*(ch0_y[frame]-ch1_y[frame]))**2)) # ap2-dnm2 separation\n",
    "\n",
    "            channel_0_1_separations_arpc3_negative.append(channel_0_1_separation_track)\n",
    "         \n",
    "            ap2_x_positions = ch0_x\n",
    "            ap2_y_positions = ch0_y     \n",
    "        \n",
    "            num_before=5\n",
    "            ap2movement = []\n",
    "            for dnm2_index in range(dnm2_peak-num_before,dnm2_peak):\n",
    "\n",
    "                try: \n",
    "\n",
    "                    ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "                    ap2movement.append(ap2temp)\n",
    "\n",
    "                except Exception:\n",
    "\n",
    "                    ap2movement.append(np.NaN)\n",
    "\n",
    "            average_ap2_movement_before_dnm2_peak_arpc3_negative.append(np.nanmean(ap2movement))            \n",
    "\n",
    "            num_after=5\n",
    "            ap2movement = []\n",
    "            for dnm2_index in range(dnm2_peak,dnm2_peak+num_after):\n",
    "\n",
    "                try: \n",
    "\n",
    "                    ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "                    ap2movement.append(ap2temp)\n",
    "\n",
    "                except Exception:\n",
    "\n",
    "                    ap2movement.append(np.NaN)\n",
    "\n",
    "            average_ap2_movement_after_dnm2_peak_arpc3_negative.append(np.nanmean(ap2movement))             \n",
    "          \n",
    "    print('fraction of events with arpc3', str(num_with_mode/(num_with_mode+num_no_neighbors)))\n",
    "    fraction_arpc3_positive.append(num_with_mode/(num_with_mode+num_no_neighbors))   \n",
    "    \n",
    "    arcp3_phenotypes_split_empty_early_late.append([num_without_mode, num_early, num_late])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(unique_user_saved_outputs+'/dataframes/merged_ap2arpc3_data_zeropadding_randomized_experiments', 'rb') as f:\n",
    "    merged_results_randomized = pickle.load(f)  \n",
    "arcp3_phenotypes_split_empty_early_late_randomized = merged_results_randomized['arcp3_phenotypes_split_empty_early_late']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions_dataframe = []\n",
    "condition = 'randomized_data'\n",
    "for exp in range(len(arcp3_phenotypes_split_empty_early_late_randomized)):\n",
    "    temp_outcomes = arcp3_phenotypes_split_empty_early_late_randomized[exp]\n",
    "#     print(temp_outcomes)\n",
    "    total_events_exp = np.sum(temp_outcomes)\n",
    "    fraction_empty = temp_outcomes[0]/total_events_exp\n",
    "    fraction_early = temp_outcomes[1]/total_events_exp\n",
    "    fraction_late = temp_outcomes[2]/total_events_exp\n",
    "    fractions_dataframe.append([fraction_empty, 'negative', exp, condition])\n",
    "    fractions_dataframe.append([fraction_early, 'early', exp, condition])\n",
    "    fractions_dataframe.append([fraction_late, 'late', exp, condition])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'real_data'\n",
    "for exp in range(len(arcp3_phenotypes_split_empty_early_late)):\n",
    "    temp_outcomes = arcp3_phenotypes_split_empty_early_late[exp]\n",
    "#     print(temp_outcomes)\n",
    "    total_events_exp = np.sum(temp_outcomes)\n",
    "    fraction_empty = temp_outcomes[0]/total_events_exp\n",
    "    fraction_early = temp_outcomes[1]/total_events_exp\n",
    "    fraction_late = temp_outcomes[2]/total_events_exp\n",
    "    fractions_dataframe.append([fraction_empty, 'negative', exp, condition])\n",
    "    fractions_dataframe.append([fraction_early, 'early', exp, condition])\n",
    "    fractions_dataframe.append([fraction_late, 'late', exp, condition])\n",
    "dataframe_arpc3_phenotype = pd.DataFrame(data=fractions_dataframe, \n",
    "                                         columns=['fraction',\n",
    "                                                  'phenotype',\n",
    "                                                  'experiment_number',\n",
    "                                                  'condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_arpc3_phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.figure(dpi=500, figsize=(5,5))\n",
    "sns.stripplot(x=\"condition\", \n",
    "              y=\"fraction\", \n",
    "              data=dataframe_arpc3_phenotype,\n",
    "              hue='phenotype',\n",
    "              dodge=True,\n",
    "              order=['real_data', 'randomized_data'])\n",
    "plt.ylim([0,1])\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/arpc3_phenotype_real_vs_randomized.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_to_save = ['ch0_vectors_arpc3_positive',\n",
    "                  'ch1_vectors_arpc3_positive',\n",
    "                  'ch2_vectors_arpc3_positive',\n",
    "                  'channel_0_1_separations_arpc3_positive',\n",
    "                  'channel_0_2_separations_arpc3_positive',\n",
    "                  'channel_1_2_separations_arpc3_positive',\n",
    "                  'final_separations_ap2arpc3_arpc3_positive',\n",
    "                  'initial_separations_ap2arpc3_arpc3_positive',\n",
    "                  'ap2_arpc3_separation_at_dnm2_peak_arpc3_positive',\n",
    "                  'ap2_arpc3_separation_at_arpc3_peak_arpc3_positive',\n",
    "                  'ap2_arpc3_separation_at_ap2_peak_arpc3_positive',\n",
    "                  'ap2_lifetime_arpc3_positive',\n",
    "                  'arpc3_lifetime_arpc3_positive',\n",
    "                  'max_separation_ap2_arpc3_arpc3_positive',\n",
    "                  'max_separation_ap2_dnm2_arpc3_positive',\n",
    "                  'max_separation_dnm2_arpc3_arpc3_positive',\n",
    "                  'num_frames_associated_arpc3_positive',\n",
    "                  'time_ap2_appearance_to_dnm2_peak_arpc3_positive',\n",
    "                  'maximum_ap2_intensity_arpc3_positive',\n",
    "                  'maximum_dnm2_intensity_arpc3_positive',\n",
    "                  'maximum_arpc3_intensity_arpc3_positive',\n",
    "                  'pval_arpc3_ccps_arpc3_positive',\n",
    "                  'time_arpc3_appearance_to_dnm2_peak_arpc3_positive',\n",
    "                  'fraction_arpc3_positive',\n",
    "                  'ccps_arpc3_positive',\n",
    "                  'experiment_number_arpc3_positive',\n",
    "                  'average_ap2_movement_before_dnm2_peak_arpc3_positive',\n",
    "                  'average_ap2_movement_after_dnm2_peak_arpc3_positive',\n",
    "                  'average_ap2_movement_before_dnm2_peak_arpc3_negative',\n",
    "                  'average_ap2_movement_after_dnm2_peak_arpc3_negative',\n",
    "                  'ap2_arpc3_separation_average_arpc3_positive',\n",
    "                  'ch0_vectors_arpc3_negative',\n",
    "                  'ch1_vectors_arpc3_negative',\n",
    "                  'channel_0_1_separations_arpc3_negative',\n",
    "                  'ccps_arpc3_negative',\n",
    "                  'time_ap2_appearance_to_dnm2_peak_arpc3_negative',\n",
    "                  'ap2_lifetime_arpc3_negative',\n",
    "                  'experiment_number_arpc3_negative',\n",
    "                  'significant_arpc3_at_dnm2_peak_arpc3_positive',\n",
    "                  'arcp3_phenotypes_split_empty_early_late',\n",
    "                  'absolute_ap2_x_position_arpc3_positive',\n",
    "                  'absolute_ap2_y_position_arpc3_positive']\n",
    "\n",
    "merged_results = {}\n",
    "for array in arrays_to_save:\n",
    "    \n",
    "    merged_results[array] = locals()[array]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ccps_arpc3_positive), len(ccps_arpc3_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_frames_associated_arpc3_positive), len(ap2_arpc3_separation_at_dnm2_peak_arpc3_positive), len(significant_arpc3_at_dnm2_peak_arpc3_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(unique_user_saved_outputs+'/dataframes/merged_ap2arpc3_data_zeropadding', 'wb') as f:\n",
    "    pickle.dump(merged_results, f)   \n",
    "    \n",
    "np.save(unique_user_saved_outputs+'/dataframes/ccps_arpc3_negative_zeropadding', ccps_arpc3_negative)\n",
    "    \n",
    "np.save(unique_user_saved_outputs+'/dataframes/ccps_arpc3_positive_zeropadding', ccps_arpc3_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP2 motility before and after scission, comparing ARPC3+/-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.figure(dpi=500, figsize=(5,5))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('average movement (microns)')\n",
    "plt.ylabel('cumulative frequency')\n",
    "ax = plt.hist(average_ap2_movement_before_dnm2_peak_arpc3_negative, bins='auto', color='blue', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3- before')\n",
    "ax = plt.hist(average_ap2_movement_before_dnm2_peak_arpc3_positive, bins='auto', color='orange', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3+ before')\n",
    "ax = plt.hist(average_ap2_movement_after_dnm2_peak_arpc3_negative, linestyle='--', bins='auto', color='blue', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3- after')\n",
    "ax = plt.hist(average_ap2_movement_after_dnm2_peak_arpc3_positive, linestyle='--', bins='auto', color='orange', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3+ after')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('AP2 motility before and after scission')\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/ap2movementbeforeafterarpc3plusminus_zeropadding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/ap2movementbeforeafterarpc3plusminus_zeropadding.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP2 motility before and after scission, comparing ARPC3+/-, only ARPC3 events present at scission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.figure(dpi=500, figsize=(5,5))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('average movement (microns)')\n",
    "plt.ylabel('cumulative frequency')\n",
    "ax = plt.hist(average_ap2_movement_before_dnm2_peak_arpc3_negative, bins='auto', color='blue', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3- before')\n",
    "ax = plt.hist(np.array(average_ap2_movement_before_dnm2_peak_arpc3_positive)[np.where(np.array(significant_arpc3_at_dnm2_peak_arpc3_positive)==1)], bins='auto', color='orange', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3+ before')\n",
    "ax = plt.hist(average_ap2_movement_after_dnm2_peak_arpc3_negative, linestyle='--', bins='auto', color='blue', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3- after')\n",
    "ax = plt.hist(np.array(average_ap2_movement_after_dnm2_peak_arpc3_positive)[np.where(np.array(significant_arpc3_at_dnm2_peak_arpc3_positive)==1)], linestyle='--', bins='auto', color='orange', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3+ after')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('AP2 motility before and after scission')\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/fig_4c_ap2movementbeforeafterarpc3plusminus_onlysigarpc3atscission_zeropadding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/fig_4c_ap2movementbeforeafterarpc3plusminus_onlysigarpc3atscission_zeropadding.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motility_plus_before = np.array(average_ap2_movement_before_dnm2_peak_arpc3_positive)[np.where(np.array(significant_arpc3_at_dnm2_peak_arpc3_positive)==1)]\n",
    "motility_plus_after = np.array(average_ap2_movement_after_dnm2_peak_arpc3_positive)[np.where(np.array(significant_arpc3_at_dnm2_peak_arpc3_positive)==1)]\n",
    "\n",
    "merged_motility = average_ap2_movement_before_dnm2_peak_arpc3_negative\n",
    "merged_motility = np.concatenate((merged_motility, average_ap2_movement_after_dnm2_peak_arpc3_negative))\n",
    "merged_motility = np.concatenate((merged_motility, motility_plus_before.flatten()))\n",
    "merged_motility = np.concatenate((merged_motility, motility_plus_after.flatten()))\n",
    "\n",
    "labels = [0 for _ in range(len(average_ap2_movement_before_dnm2_peak_arpc3_negative))]\n",
    "labels += [1 for _ in range(len(average_ap2_movement_after_dnm2_peak_arpc3_negative))]\n",
    "labels += [2 for _ in range(len(motility_plus_before))]\n",
    "labels += [4 for _ in range(len(motility_plus_after))]\n",
    "\n",
    "merged_data_motility = np.array((merged_motility, labels)).T\n",
    "\n",
    "df_motility = pd.DataFrame(data=merged_data_motility, columns=['motility', 'position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "ax = sns.boxplot(data=df_motility, x='position', y='motility')\n",
    "box0 = ax.artists[0]\n",
    "box0.set_facecolor('blue')\n",
    "box1 = ax.artists[1]\n",
    "box1.set_facecolor('blue')\n",
    "box2 = ax.artists[2]\n",
    "box2.set_facecolor('orange')\n",
    "box3 = ax.artists[3]\n",
    "box3.set_facecolor('orange')\n",
    "\n",
    "ax.set_xticklabels(['ARPC3-\\nbefore',\n",
    "                    'ARPC3-\\nafter',\n",
    "                    'ARPC3+\\nbefore',\n",
    "                    'ARPC3+\\nafter']);\n",
    "ax.set_xlabel('ARPC3 recruitment +/-, timing relative to scission')\n",
    "plt.ylabel('average movement (microns)')\n",
    "plt.ylim([0,0.2])\n",
    "plt.tight_layout()\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/fig_4c_boxplot_motility_sig_arpc3_at_scission.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/fig_4c_boxplot_motility_sig_arpc3_at_scission.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP2 motility before and after scission, comparing ARPC3+/-, only ARPC3 events not present at scission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.figure(dpi=500, figsize=(5,5))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('average movement (microns)')\n",
    "plt.ylabel('cumulative frequency')\n",
    "ax = plt.hist(average_ap2_movement_before_dnm2_peak_arpc3_negative, bins='auto', color='blue', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3- before')\n",
    "ax = plt.hist(np.array(average_ap2_movement_before_dnm2_peak_arpc3_positive)[np.where(np.array(significant_arpc3_at_dnm2_peak_arpc3_positive)==0)], bins='auto', color='orange', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3+ before')\n",
    "ax = plt.hist(average_ap2_movement_after_dnm2_peak_arpc3_negative, linestyle='--', bins='auto', color='blue', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3- after')\n",
    "ax = plt.hist(np.array(average_ap2_movement_after_dnm2_peak_arpc3_positive)[np.where(np.array(significant_arpc3_at_dnm2_peak_arpc3_positive)==0)], linestyle='--', bins='auto', color='orange', alpha=1, cumulative=True, histtype='step', density=True, label='ARPC3+ after')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('AP2 motility before and after scission')\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/ap2movementbeforeafterarpc3plusminus_onlynonsigarpc3atscission_zeropadding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/ap2movementbeforeafterarpc3plusminus_onlynonsigarpc3atscission_zeropadding.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
