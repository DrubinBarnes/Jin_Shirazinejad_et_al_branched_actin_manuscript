{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "otherwise-doubt",
   "metadata": {},
   "source": [
    "Cyna Shirazinejad, 7/7/21\n",
    "\n",
    "# Notebook 4: compare clustering models\n",
    "\n",
    "outline:\n",
    "    \n",
    "* generate clustering models using alternative combinations of training sets\n",
    "* check if DNM2+ events are uniformly selected by alternative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-moderator",
   "metadata": {},
   "source": [
    "# import all necessary Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pingouin as pg\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "unique_user_saved_outputs = str(np.load('unique_user_saved_outputs.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-perspective",
   "metadata": {},
   "source": [
    "# load dataframe from notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe with all track features with corresponding labels for experiment number and number of imaging channels\n",
    "df_merged_features = pd.read_csv(unique_user_saved_outputs+'/dataframes/df_merged_features.zip')\n",
    "df_pcs_normal_scaled_with_gmm_cluster = pd.read_csv(unique_user_saved_outputs+'/dataframes/df_pcs_normal_scaled_with_gmm_cluster.zip')\n",
    "feature_units = np.load(unique_user_saved_outputs+'/dataframes/feature_units.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-allen",
   "metadata": {},
   "source": [
    "# look for effects of different training data combinations on results on DNM2+ predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'magenta', 'grey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_combinations = [] # all combinations of experiments\n",
    "experiment_numbers = set(df_merged_features['experiment_number'].values)\n",
    "for L in range(0, len(experiment_numbers)+1):\n",
    "    for subset in itertools.combinations(experiment_numbers, L):\n",
    "        experiment_combinations.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-eagle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_merged_features\n",
    "mean_dnm2_max = [] # mean DNM2 intensity across DNM2+ events in model\n",
    "std_dnm2_max = [] # std \"\"\n",
    "num_exp_combo = [] # number of experiments in training data\n",
    "fraction_dnm2_positive = [] # fraction of events per model that are dnm2+ (only looking at experiments used for training)\n",
    "\n",
    "fraction_per_experiment_predicted_dnm2 = [] # check every experiment individually against model for % dnm2+ (even for experiments not used in training)\n",
    "experiment_dnm2_checked = [] # the experiment being checked against every model\n",
    "num_exp_combo_per_exp = [] # the number of experiments used for training the model\n",
    "exp_training_single_combo = [] # only used when a single experiment is used for training, but keeps track of the 'first' experiment used in the combo of training examples\n",
    "\n",
    "indices_dnm2_positive_all_models = []\n",
    "\n",
    "for i, combo in tqdm(enumerate(experiment_combinations)):\n",
    "\n",
    "    if list(combo): # do not look at empty set \n",
    "\n",
    "        features_combo = df[df['experiment_number'].isin(list(combo))].values[:,:30] # the raw features of events in experiments used for training\n",
    "        normal_scaler_combo = preprocessing.QuantileTransformer(output_distribution='normal', random_state=817) # scale the features\n",
    "        normal_scaled_data_combo = normal_scaler_combo.fit_transform(features_combo)\n",
    " \n",
    "        pc_model_combo = PCA(n_components=2, random_state=817) # project\n",
    "        reduced_data_combo = pc_model_combo.fit_transform(normal_scaled_data_combo)\n",
    "        \n",
    "        gmm_combo = GMM(n_components=5, random_state=817) # cluster\n",
    "\n",
    "        gmm_prediction_combo = gmm_combo.fit_predict(reduced_data_combo)\n",
    "        \n",
    "        mean_dnm2_cluster = [] # find which cluster has the highest dnm2 signal\n",
    "        for i in range(5):\n",
    "\n",
    "            max_dnm2_clusters = features_combo[:,2][np.where(gmm_prediction_combo==i)[0]]\n",
    "\n",
    "            mean_dnm2_cluster.append(np.mean(max_dnm2_clusters))\n",
    "\n",
    "        cluster_max_dnm2 = np.argmax(mean_dnm2_cluster) # index of cluster with highest dnm2 signal, on average\n",
    "        \n",
    "        indices_dnm2_positive = np.where(gmm_prediction_combo==cluster_max_dnm2)[0] # event indices of dnm2+ events\n",
    "        \n",
    "        dnm2_max_combo_dnm2_positive = features_combo[:,2][indices_dnm2_positive] # max dnm2 signal per event for dnm2+\n",
    "        \n",
    "        mean_dnm2_max.append(np.mean(dnm2_max_combo_dnm2_positive))\n",
    "        std_dnm2_max.append(np.std(dnm2_max_combo_dnm2_positive))\n",
    "        num_exp_combo.append(len(list(combo)))\n",
    "        fraction_dnm2_positive.append(len(indices_dnm2_positive)/len(gmm_prediction_combo))\n",
    "#         print(len(indices_dnm2_positive)/len(gmm_prediction_combo))\n",
    "\n",
    "        all_features = df.values[:,:30] # all experiments\n",
    "        \n",
    "        scaled_all_data = normal_scaler_combo.transform(all_features) \n",
    "        # scale all data (data that already has been scaled should be \n",
    "        # where it was above, new data will be scaled using the \n",
    "        # quantiles set by this already-trained scaler)\n",
    "        \n",
    "        all_pcs = pc_model_combo.transform(scaled_all_data) # project and cluster all data\n",
    "        \n",
    "        all_gmm_preds = gmm_combo.predict(all_pcs)\n",
    "        \n",
    "        all_indices_dnm2_positive = np.where(all_gmm_preds==cluster_max_dnm2)[0]\n",
    "        \n",
    "        indices_dnm2_positive_all_models.append(all_indices_dnm2_positive)\n",
    "        \n",
    "        for exp_num in set(df['experiment_number'].values): # iterate over all experiments\n",
    "            \n",
    "            indices_experiment = list(df[df['experiment_number'].isin([exp_num])].index) # find events for experiment\n",
    "            \n",
    "            indices_dnm2_pos_exp = set(indices_experiment).intersection(all_indices_dnm2_positive) # find dnm2+ events in experiment\n",
    "#             print(len(indices_dnm2_pos_exp)/len(indices_experiment))\n",
    "            fraction_per_experiment_predicted_dnm2.append(len(indices_dnm2_pos_exp)/len(indices_experiment)) # fraction of events in experiment that are dnm2+\n",
    "            experiment_dnm2_checked.append(exp_num) # exp number used for inference\n",
    "            num_exp_combo_per_exp.append(len(list(combo))) # num experiments used for training\n",
    "            exp_training_single_combo.append(combo[0]) # this will be checked only for len(combo)==1, but find the datapoint used for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(unique_user_saved_outputs+'/dataframes/mean_dnm2_max', mean_dnm2_max)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/std_dnm2_max', std_dnm2_max)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/num_exp_combo', num_exp_combo)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/fraction_dnm2_positive', fraction_dnm2_positive)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/fraction_per_experiment_predicted_dnm2', fraction_per_experiment_predicted_dnm2)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/experiment_dnm2_checked', experiment_dnm2_checked)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/num_exp_combo_per_exp', num_exp_combo_per_exp)\n",
    "np.save(unique_user_saved_outputs+'/dataframes/exp_training_single_combo', exp_training_single_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dnm2_max = np.load(unique_user_saved_outputs+'/dataframes/mean_dnm2_max.npy')\n",
    "std_dnm2_max = np.load(unique_user_saved_outputs+'/dataframes/std_dnm2_max.npy')\n",
    "num_exp_combo = np.load(unique_user_saved_outputs+'/dataframes/num_exp_combo.npy')\n",
    "fraction_dnm2_positive = np.load(unique_user_saved_outputs+'/dataframes/fraction_dnm2_positive.npy')\n",
    "fraction_per_experiment_predicted_dnm2 = np.load(unique_user_saved_outputs+'/dataframes/fraction_per_experiment_predicted_dnm2.npy')\n",
    "experiment_dnm2_checked = np.load(unique_user_saved_outputs+'/dataframes/experiment_dnm2_checked.npy')\n",
    "num_exp_combo_per_exp = np.load(unique_user_saved_outputs+'/dataframes/num_exp_combo_per_exp.npy')\n",
    "exp_training_single_combo = np.load(unique_user_saved_outputs+'/dataframes/exp_training_single_combo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, axes = plt.subplots(1,3, dpi=500, figsize=(8,2))\n",
    "axes[0].hist(mean_dnm2_max, bins='doane', density=True);\n",
    "axes[0].set_xlabel('mean DNM2 max intensity \\nfor DNM2+ events in model')\n",
    "axes[1].hist(std_dnm2_max, bins='auto', density=True);\n",
    "axes[1].set_xlabel('standard deviation of DNM2 max\\nintensity for DNM2+ events in model')\n",
    "axes[2].hist(fraction_dnm2_positive, bins='auto', density=True);\n",
    "axes[2].set_xlabel('fraction of DNM2+ events in model')\n",
    "axes[0].set_ylabel('frequency density')\n",
    "axes[1].set_ylabel('frequency density')\n",
    "axes[2].set_ylabel('frequency density')\n",
    "plt.tight_layout()\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/stats_dnm2pos_variousmodels.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/stats_dnm2pos_variousmodels.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plt.figure(figsize=(15,5), dpi=1000)\n",
    "\n",
    "fraction_dnm2pos_num_exp_training_and_exp_num = []\n",
    "\n",
    "for i in range(len(fraction_per_experiment_predicted_dnm2)):\n",
    "    \n",
    "    num_in_combo = num_exp_combo_per_exp[i]\n",
    "#     print(int(experiment_dnm2_checked[i]))\n",
    "    color = colors[int(experiment_dnm2_checked[i])]\n",
    "#     print(fraction_per_experiment_predicted_dnm2[i])\n",
    "#     print(num_in_combo+0.25, fraction_per_experiment_predicted_dnm2[i])\n",
    "#     print(num_in_combo+0.1+0.1*int(experiment_dnm2_checked[i]))\n",
    "#     print(color)\n",
    "    plt.plot(num_in_combo+0.1+0.1*int(experiment_dnm2_checked[i]), fraction_per_experiment_predicted_dnm2[i], '.', color=color, markersize=1)\n",
    "    \n",
    "    fraction_dnm2pos_num_exp_training_and_exp_num.append([int(experiment_dnm2_checked[i]), num_in_combo, fraction_per_experiment_predicted_dnm2[i]])\n",
    "    \n",
    "plt.plot(num_exp_combo, fraction_dnm2_positive, '.b')\n",
    "for i in range(8):\n",
    "    plt.plot(num_exp_combo[i], fraction_dnm2_positive[i], '.', c=colors[i])\n",
    "for i in range(1,9):\n",
    "    plt.axvspan(i-0.05, i+0.05, color='yellow', alpha=0.5)\n",
    "plt.ylabel('fraction of events DNM2 positive')\n",
    "x_ticks = []\n",
    "x_tick_labels = []\n",
    "for i in range(8):\n",
    "    if i==0:\n",
    "        x_tick_labels.append('*'+str(i+1)+' total experiment')\n",
    "    else:\n",
    "        x_tick_labels.append('*'+str(i+1)+' total experiments')\n",
    "    x_ticks.append(i+1)\n",
    "    for j in range(8):\n",
    "        x_tick_labels.append('**'+'experiment '+str(j))\n",
    "        x_ticks.append(i+1+0.1+0.1*j)\n",
    "plt.xticks(x_ticks, labels=x_tick_labels, rotation=90);\n",
    "\n",
    "means_each_exp_per_num_datasets = [[] for i in range(8)]\n",
    "\n",
    "for i in range(1,9):\n",
    "    \n",
    "    indices_num_experiments = np.where(np.array(num_exp_combo)==i)[0]\n",
    "    fractions_n_exp = np.mean(np.array(fraction_dnm2_positive)[indices_num_experiments])\n",
    "    mean_fractions_overlap = np.mean(np.array(fraction_dnm2_positive)[indices_num_experiments])\n",
    "    variance_fractions = np.var(np.array(fraction_dnm2_positive)[indices_num_experiments])\n",
    "    max_y = np.max(np.array(fraction_dnm2_positive)[indices_num_experiments])\n",
    "    plt.text(i, \n",
    "             0.43, \n",
    "             'mean: ' + \"{:.2e}\".format(mean_fractions_overlap)+ '\\nvariance: ' + \"{:.2e}\".format(variance_fractions), \n",
    "             rotation=90, \n",
    "             horizontalalignment='center', \n",
    "             fontsize=3,\n",
    "             backgroundcolor='cyan',\n",
    "             verticalalignment='top')\n",
    "    plt.axhline(fractions_n_exp, color='b', alpha=0.1, linestyle='-')\n",
    "    \n",
    "    for j in range(1,9):\n",
    "        indices_exp_individual = np.where(np.array(experiment_dnm2_checked)==j-1)[0]\n",
    "        indices_num_in_combo = np.where(np.array(num_exp_combo_per_exp)==i)[0]\n",
    "        indices_overlap = list(set(indices_exp_individual).intersection(indices_num_in_combo))\n",
    "        fractions_overlap = np.array(fraction_per_experiment_predicted_dnm2)[indices_overlap]\n",
    "        mean_fractions_overlap = np.mean(fractions_overlap)\n",
    "        means_each_exp_per_num_datasets[j-1].append((j-1, mean_fractions_overlap))\n",
    "        plt.axhline(mean_fractions_overlap, color=colors[j-1], alpha=0.1)\n",
    "        variance_fractions = np.var(fractions_overlap)\n",
    "        max_y = np.max(np.array(fractions_overlap))\n",
    "        plt.text(i+0.1*j, \n",
    "                 0.43, \n",
    "                 'mean: ' + \"{:.2e}\".format(mean_fractions_overlap)+ '\\nvariance: ' + \"{:.2e}\".format(variance_fractions), \n",
    "                 rotation=90, \n",
    "                 horizontalalignment='center', \n",
    "                 backgroundcolor='white', \n",
    "                 fontsize=3,\n",
    "                 verticalalignment='top')\n",
    "    \n",
    "plt.ylim(0, 0.45)\n",
    "plt.xlim(0.8, 9)\n",
    "plt.yticks(list(np.arange(0,0.5,0.05)), labels=[str(np.around(x,2)) for x in np.arange(0,0.5,0.05)], rotation=90, verticalalignment='center')\n",
    "plt.title(\"*: training data, **: testing data;\"+\n",
    "          \"\\ntraining data predictions are computed for all combinations of N experiments' models;\"+\n",
    "          \"\\ntesting data is subject to prediction for every experiment against all training models;\"+\n",
    "          \"\\ncolors in single-experiment training models correspond to testing data predictions\")\n",
    "# plt.tight_layout()\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/boostrap_fraction_dnm2_positive.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/boostrap_fraction_dnm2_positive.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "for i in range(8):\n",
    "    \n",
    "    means_exp = means_each_exp_per_num_datasets[i]\n",
    "    for mean in means_exp:\n",
    "#         print(mean[0], mean[1])\n",
    "#         print(colors[i])\n",
    "        plt.plot(mean[0], mean[1], '.', color=colors[i], markersize=5)\n",
    "for i in range(8):\n",
    "    plt.plot(i, fraction_dnm2_positive[i], '.', c=colors[i], markersize=10, marker='*')  \n",
    "plt.axhline(fraction_dnm2_positive[-1])\n",
    "# for j,i in enumerate(range(8)):\n",
    "#     plt.plot(j, fraction_per_experiment_predicted_dnm2[-i], c=colors[j], marker='o')\n",
    "k=0\n",
    "for i in range(len(fraction_per_experiment_predicted_dnm2)):\n",
    "    if num_exp_combo_per_exp[i]==8:\n",
    "        plt.plot(experiment_dnm2_checked[i], fraction_per_experiment_predicted_dnm2[i], c=colors[k], marker='o')\n",
    "        k+=1\n",
    "plt.ylim(0.04, 0.23)\n",
    "plt.xlabel('experiment number')\n",
    "plt.ylabel('fraction DNM2 positive from\\npredictions of each N-dataset(s) training model')\n",
    "plt.title('- blue line is the aggregate model fraction\\n- stars are predictions from a single dataset model\\n- large circles are aggregate model predictions per experiment')\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/boostrapped_dnm2_pos_fractions_averages_across_training_models_ndatasets_mean_and_individual_pred_labeled.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/boostrapped_dnm2_pos_fractions_averages_across_training_models_ndatasets_mean_and_individual_pred_labeled.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraction_num_training_and_exp_num = pd.DataFrame(data=fraction_dnm2pos_num_exp_training_and_exp_num, columns=['experiment', 'number_training', 'fraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe for subsequent notebooks\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name=unique_user_saved_outputs+'/dataframes/df_fraction_num_training_and_exp_num.csv')  \n",
    "\n",
    "df_fraction_num_training_and_exp_num.to_csv(unique_user_saved_outputs+'/dataframes/df_fraction_num_training_and_exp_num.zip', index=False,\n",
    "                                                          compression=compression_opts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraction_num_training_and_exp_num = pd.read_csv(unique_user_saved_outputs+'/dataframes/df_fraction_num_training_and_exp_num.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.rcParams['figure.dpi']=500\n",
    "sns.catplot(data=df_fraction_num_training_and_exp_num, x='experiment', y='fraction', hue='number_training')\n",
    "plt.ylabel('fraction DNM2+')\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/fractiondnm2_exp_num_training.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/fractiondnm2_exp_num_training.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.homoscedasticity(data=df_fraction_num_training_and_exp_num, dv='fraction', group='experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.anova(data=df_fraction_num_training_and_exp_num, dv='fraction', between='experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_output = pg.pairwise_tukey(data=df_fraction_num_training_and_exp_num, dv='fraction', between='experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_matrix = np.zeros((8,8))\n",
    "comparison_matrix = np.zeros((8,8))\n",
    "\n",
    "tukey_values = tukey_output.values\n",
    "\n",
    "compared_indices = [(int(tukey_values[row, 0]), int(tukey_values[row, 1])) for row in range(tukey_values.shape[0])]\n",
    "possible_indices = [(i, j) for i in range(8) for j in range(8)]\n",
    "\n",
    "for row in range(tukey_values.shape[0]):\n",
    "    \n",
    "    tukey_matrix[int(tukey_values[row, 0]), int(tukey_values[row, 1])] = tukey_values[row, -2]\n",
    "    \n",
    "for idx in possible_indices:\n",
    "    \n",
    "    if idx not in compared_indices:\n",
    "        \n",
    "        tukey_matrix[idx[0], idx[1]] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(mpl.colors.Normalize): # https://stackoverflow.com/questions/7404116/defining-the-midpoint-of-a-colormap-in-matplotlib\n",
    "    def __init__(self, vmin, vmax, midpoint=0, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mpl.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        normalized_min = max(0, 1 / 2 * (1 - abs((self.midpoint - self.vmin) / (self.midpoint - self.vmax))))\n",
    "        normalized_max = min(1, 1 / 2 * (1 + abs((self.vmax - self.midpoint) / (self.midpoint - self.vmin))))\n",
    "        normalized_mid = 0.5\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [normalized_min, normalized_mid, normalized_max]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams['figure.dpi']=500\n",
    "fig, axs = plt.subplots(1,1, constrained_layout=True, figsize=(3,3))\n",
    "\n",
    "cmap = 'plasma'\n",
    "\n",
    "sc = axs.imshow(comparison_matrix, \n",
    "                alpha=1, \n",
    "                origin='lower', \n",
    "                interpolation='none', \n",
    "                cmap=cmap,\n",
    "                aspect='auto')\n",
    "\n",
    "vmin = 0\n",
    "vmax = 0.05\n",
    "norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0.01)\n",
    "cmap = 'bwr'\n",
    "\n",
    "sc = axs.imshow(tukey_matrix, \n",
    "                alpha=0.9, \n",
    "                origin='lower', \n",
    "                interpolation='none', \n",
    "                cmap=cmap,\n",
    "                norm=norm, \n",
    "                aspect='equal')\n",
    "cba = fig.colorbar(sc,shrink=1, location='right')\n",
    "cba.set_label('p-value', rotation=270, labelpad=15)\n",
    "cba.set_alpha(1)\n",
    "cba.draw_all()\n",
    "\n",
    "plt.ylabel('experiment number')\n",
    "plt.xlabel('experiment number')\n",
    "\n",
    "\n",
    "# Major ticks\n",
    "axs.set_xticks(np.arange(8))\n",
    "axs.set_yticks(np.arange(8))\n",
    "\n",
    "# Labels for major ticks\n",
    "axs.set_xticklabels(np.arange(8))\n",
    "axs.set_yticklabels(np.arange(8))\n",
    "\n",
    "# Minor ticks\n",
    "axs.set_xticks(np.arange(-.5, 8, 1), minor=True)\n",
    "axs.set_yticks(np.arange(-.5, 8, 1), minor=True)\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    plt.plot(np.arange(-1,9), np.arange(-1,9)+i, 'k')\n",
    "    \n",
    "plt.xlim(-0.5,7.5)\n",
    "plt.ylim(-0.5,7.5)\n",
    "\n",
    "# Gridlines based on minor ticks\n",
    "axs.grid(which='minor', color='w', linestyle='-', linewidth=3)\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/tukey_matrix_dnm2_comparison.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/tukey_matrix_dnm2_comparison.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_models_event_dnm2pos = np.zeros((df_merged_features.shape[0]))\n",
    "for dnm2_pos_list in indices_dnm2_positive_all_models:\n",
    "    \n",
    "    for idx in dnm2_pos_list:\n",
    "        \n",
    "        fraction_of_models_event_dnm2pos[idx] = fraction_of_models_event_dnm2pos[idx] + 1\n",
    "\n",
    "fraction_of_models_event_dnm2pos = 1/len(indices_dnm2_positive_all_models)*fraction_of_models_event_dnm2pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_scaler = preprocessing.QuantileTransformer(output_distribution='normal', random_state=817)\n",
    "normal_scaled_data = normal_scaler.fit_transform(df_merged_features.values[:,:len(feature_units)])\n",
    "\n",
    "pc_model = PCA(n_components=2, random_state=817)\n",
    "reduced_data = pc_model.fit_transform(normal_scaled_data)\n",
    "\n",
    "gmm = GMM(n_components=5, random_state=817)\n",
    "\n",
    "gmm_prediction = gmm.fit_predict(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi']=500\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5), dpi=500)\n",
    "\n",
    "h=0.01 # https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 4, reduced_data[:, 1].max() + 3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = gmm.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = np.max(Z, axis=1)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "vmin = 0.4\n",
    "vmax = 1\n",
    "norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0.99999999)\n",
    "cmap = 'bwr'\n",
    "\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           aspect='auto', origin='lower', alpha=0.2,\n",
    "           norm=norm,\n",
    "           cmap=cmap)\n",
    "\n",
    "sc = ax.scatter(df_pcs_normal_scaled_with_gmm_cluster['PC-0'],\n",
    "           df_pcs_normal_scaled_with_gmm_cluster['PC-1'],\n",
    "           s=1,\n",
    "           alpha=0.1)\n",
    "\n",
    "plt.xlabel('PC-0')\n",
    "plt.ylabel('PC-1')\n",
    "plt.ylim([-7, 11])\n",
    "plt.xlim([-9, 13])\n",
    "plt.xticks([-5, 0, 5, 10], labels=[-5, 0, 5, 10])\n",
    "plt.yticks([-5, 0, 5, 10], labels=[-5, 0, 5, 10])\n",
    "plt.title('principal components of valid tracks\\nmapped to feature-space\\nblue lines indicate 95% probability\\nboundaries between clusters')\n",
    "plt.tight_layout()\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/cluster_boundaries.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/cluster_boundaries.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.style.use('default')\n",
    "# plt.rcParams['figure.dpi']=500\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5), dpi=500)\n",
    "\n",
    "h=0.01 # https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 4, reduced_data[:, 1].max() + 3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = gmm.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = np.max(Z, axis=1)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "vmin = 0.4\n",
    "vmax = 1\n",
    "norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0.99999999)\n",
    "cmap = 'bwr'\n",
    "\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           aspect='auto', origin='lower', alpha=0.6,\n",
    "           norm=norm,\n",
    "           cmap=cmap)\n",
    "\n",
    "sc = ax.scatter(df_pcs_normal_scaled_with_gmm_cluster['PC-0'],\n",
    "           df_pcs_normal_scaled_with_gmm_cluster['PC-1'],\n",
    "           c=fraction_of_models_event_dnm2pos,\n",
    "           s=1,\n",
    "           alpha=1)\n",
    "cba = fig.colorbar(sc,shrink=1)\n",
    "cba.set_label('% of models that \\nconsider event DNM2+', rotation=270, labelpad=25)\n",
    "cba.set_alpha(1)\n",
    "plt.xlabel('PC-0')\n",
    "plt.ylabel('PC-1')\n",
    "plt.ylim([-7, 11])\n",
    "plt.xlim([-9, 13])\n",
    "plt.xticks([-5, 0, 5, 10], labels=[-5, 0, 5, 10])\n",
    "plt.yticks([-5, 0, 5, 10], labels=[-5, 0, 5, 10])\n",
    "plt.title('principal components of valid tracks\\nmapped to feature-space\\n blue lines indicate boundaries between clusters')\n",
    "plt.tight_layout()\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/fraction_models_consider_event_dnm2pos_overlaid_pcs_temp.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/fraction_models_consider_event_dnm2pos_overlaid_pcs_temp.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5), dpi=500)\n",
    "\n",
    "h=0.01 # https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 4, reduced_data[:, 1].max() + 3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = gmm.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = np.max(Z, axis=1)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "vmin = 0.4\n",
    "vmax = 1\n",
    "norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0.99999999)\n",
    "cmap = 'bwr'\n",
    "\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           aspect='auto', origin='lower', alpha=0.6,\n",
    "           norm=norm,\n",
    "           cmap=cmap)\n",
    "\n",
    "\n",
    "sc = ax.scatter(df_pcs_normal_scaled_with_gmm_cluster['PC-0'],\n",
    "           df_pcs_normal_scaled_with_gmm_cluster['PC-1'],\n",
    "           c=fraction_of_models_event_dnm2pos,\n",
    "           s=1,\n",
    "           alpha=1)\n",
    "cba = fig.colorbar(sc,shrink=1)\n",
    "cba.set_label('% of models that \\nconsider event DNM2+', rotation=270, labelpad=25)\n",
    "cba.set_alpha(1)\n",
    "plt.xlabel('PC-0')\n",
    "plt.ylabel('PC-1')\n",
    "\n",
    "plt.xticks([-5, 0, 5, 10], labels=[-5, 0, 5, 10])\n",
    "plt.yticks([-5, 0, 5, 10], labels=[-5, 0, 5, 10])\n",
    "ax.set_ylim([-7,4]);\n",
    "ax.set_xlim([4,13]);\n",
    "plt.title('principal components of valid tracks\\nmapped to feature-space')\n",
    "plt.tight_layout()\n",
    "plt.savefig(unique_user_saved_outputs+'/plots/fraction_models_consider_event_dnm2pos_overlaid_pcs_temp_zoomed.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=unique_user_saved_outputs+'/plots/fraction_models_consider_event_dnm2pos_overlaid_pcs_temp_zoomed.png', height=500, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-complement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
