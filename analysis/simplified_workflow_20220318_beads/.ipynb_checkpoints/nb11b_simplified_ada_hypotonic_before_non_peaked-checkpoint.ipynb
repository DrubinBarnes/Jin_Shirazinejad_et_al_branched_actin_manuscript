{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cyna Shirazinejad, 1/26/22\n",
    "\n",
    "# Notebook 11b: merge AP2 with ARPC3, 'zero' padding\n",
    "\n",
    "outline:\n",
    "* find ARPC3+/- events\n",
    "* measure the effect of CCP motility with ARPC3 recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import all necessary Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "from scipy import signal\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "analysis_metadata = np.load('analysis_metadata.npy', allow_pickle=True)\n",
    "sys.path.append(analysis_metadata.item().get('path_notebook')+'/cmeAnalysisPostProcessingSimplified') # add custom Python scripts to the local path\n",
    "import separate_tracking_merge_tools\n",
    "import merge_tools\n",
    "import generate_index_dictionary\n",
    "import return_track_attributes\n",
    "index_dictionary = generate_index_dictionary.return_index_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'path_outputs': '/Volumes/GoogleDrive/My Drive/Drubin Lab/ap2dynm2arcp3_project/stable_outputs_20220211', 'path_notebook': '/Users/cynashirazinejad/Documents/GitHub/Jin_Shirazinejad_et_al_branched_actin_manuscript/analysis/simplified_workflow_20220211', 'feature_units': ['seconds', 'a.u. fluorescence', 'a.u. fluorescence', 'pixels', 'pixels', 'pixels', 'pixels', 'pixels', 'seconds', 'seconds', 'seconds', 'seconds', 'seconds', 'a.u. fluorescence', 'a.u. fluorescence', 'a.u. fluorescence', 'a.u. fluorescence', 'a.u. fluorescence', 'unitless', 'a.u. fluorescence', 'a.u. fluorescence', 'a.u. fluorescence**2', 'a.u. fluorescence**2', 'unitless', 'unitless', 'unitless', 'unitless', 'counts', 'counts', 'unitless', 'unitless', 'unitless'], 'possible_track_features': ['lifetime', 'max_int_ch0', 'max_int_ch1', 'dist_traveled_ch0', 'dist_traveled_ch1', 'max_dist_between_ch0-ch1', 'md_ch0', 'md_ch1', 'time_to_peak_ch0', 'time_to_peak_ch1', 'time_after_peak_ch0', 'time_after_peak_ch1', 'time_between_peaks_ch0-ch1', 'avg_int_change_to_peak_ch0', 'avg_int_change_to_peak_ch1', 'avg_int_change_after_peak_ch0', 'avg_int_change_after_peak_ch1', 'peak_int_diff_ch0-ch1', 'ratio_max_int_ch0-ch1', 'mean_ch0', 'mean_ch1', 'variation_ch0', 'variation_ch1', 'skewness_ch0', 'skewness_ch1', 'kurtosis_ch0', 'kurtosis_ch1', 'number_significant_ch1', 'max_consecutive_significant_ch1', 'fraction_significant_ch1', 'fraction_peak_ch0', 'fraction_peak_ch1'], 'possible_track_features_labels': ['lifetime', 'max_int_ap2', 'max_int_dnm2', 'dist_traveled_ap2', 'dist_traveled_dnm2', 'max_dist_between_ap2_dnm2', 'md_ap2', 'md_dnm2', 'time_to_peak_ap2', 'time_to_peak_dnm2', 'time_after_peak_ap2', 'time_after_peak_dnm2', 'time_between_peaks_ap2_dnm2', 'avg_int_change_to_peak_ap2', 'avg_int_change_to_peak_dnm2', 'avg_int_change_after_peak_ap2', 'avg_int_change_after_peak_dnm2', 'peak_int_diff_ap2_dnm2', 'ratio_max_int_ap2_dnm2', 'mean_ap2', 'mean_dnm2', 'variation_ap2', 'variation_dnm2', 'skewness_ap2', 'skewness_dnm2', 'kurtosis_ap2', 'kurtosis_dnm2', 'number_significant_dnm2', 'max_consecutive_significant_dnm2', 'fraction_significant_dnm2', 'fraction_peak_ap2', 'fraction_peak_dnm2'], 'experiment_groups': {'ad_wildtype': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/tracking_data/AD_cellline_analysis_formatted', 'df': 'df_ad_wildtype_merged_features', 'tracks': 'merged_ad_wildtype_valid_tracks', 'number_of_track_splits': 8}, 'ada_wildtype': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/tracking_data/ADA_cellline_analysis_formatted_temp/', 'df': 'df_ada_wildtype_merged_features', 'tracks': 'merged_ada_wildtype_valid_tracks', 'number_of_track_splits': 13, 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/tracking_data/ADA_cellline_analysis_formatted_arpc3_tracking', 'name_secondary_structures': 'arpc3_wildtype_no-treatment_separate_arpc3_tracking'}, 'ada_ck666_nt': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/ck666_tracking_data_ap2dnm2', 'df': 'df_ada_ck666_nt_merged_features', 'tracks': 'merged_ada_ck666_nt_valid_tracks', 'number_of_track_splits': 12, 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/ck666_tracking_data_arpc3', 'name_secondary_structures': 'arpc3_drugs_no-treatment_separate_arpc3_tracking'}, 'ada_ck666_dmso': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/ck666_tracking_data_ap2dnm2', 'df': 'df_ada_ck666_dmso_merged_features', 'tracks': 'merged_ada_ck666_dmso_valid_tracks', 'number_of_track_splits': 9, 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/ck666_tracking_data_arpc3', 'name_secondary_structures': 'arpc3_drugs_dmso_separate_arpc3_tracking'}, 'ada_ck666_ck666': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/ck666_tracking_data_ap2dnm2', 'df': 'df_ada_ck666_ck666_merged_features', 'tracks': 'merged_ada_ck666_ck666_valid_tracks', 'number_of_track_splits': 9, 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/ck666_tracking_data_arpc3', 'name_secondary_structures': 'arpc3_drugs_ck666_separate_arpc3_tracking'}, 'ada_hypotonic_before': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/hypotonic_tracking_data_merged_211203_211208_ap2dnm2/', 'df': 'df_ada_hypotonic_before_merged_features', 'tracks': 'merged_ada_hypotonic_before_valid_tracks', 'number_of_track_splits': 10, 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/hypotonic_tracking_data_merged_211203_211208_arpc3/', 'name_secondary_structures': 'arpc3_hypotonic_before_separate_arpc3_tracking'}, 'ada_hypotonic_after': {'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/hypotonic_tracking_data_merged_211203_211208_ap2dnm2/', 'df': 'df_ada_hypotonic_after_merged_features', 'tracks': 'merged_ada_hypotonic_after_valid_tracks', 'number_of_track_splits': 10, 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/revision_tracking/hypotonic_tracking_data_merged_211203_211208_arpc3/', 'name_secondary_structures': 'arpc3_hypotonic_after_separate_arpc3_tracking'}}, 'index_DNM2positive': 0, 'number_of_clusters': 5, 'distance_best_fit': 17, 'height_best_fit': 125, 'width_best_fit': 5},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all valid arpc3 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'ada_wildtype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_metadata = analysis_metadata.item().get('experiment_groups')[experiment]\n",
    "num_tracks = experiment_metadata['number_of_track_splits']\n",
    "name_tracks = experiment_metadata['tracks']\n",
    "path_tracks_secondary = experiment_metadata['tracks_secondary']\n",
    "name_secondary_structures = experiment_metadata['name_secondary_structures']\n",
    "df_experiment = experiment_metadata['df']\n",
    "path_outputs = analysis_metadata.item().get('path_outputs')\n",
    "df_experiment = pd.read_csv(path_outputs+'/dataframes/'+df_experiment+'.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/tracking_data/ADA_cellline_analysis_formatted_temp/',\n",
       " 'df': 'df_ada_wildtype_merged_features',\n",
       " 'tracks': 'merged_ada_wildtype_valid_tracks',\n",
       " 'number_of_track_splits': 13,\n",
       " 'tracks_secondary': '/Volumes/Google Drive/My Drive/Drubin Lab/ap2dynm2arcp3_project/tracking_data/ADA_cellline_analysis_formatted_arpc3_tracking',\n",
       " 'name_secondary_structures': 'arpc3_wildtype_no-treatment_separate_arpc3_tracking'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "valid_tracks_arpc3 = [np.load(path_outputs+\n",
    "                              '/dataframes/'+\n",
    "                              name_secondary_structures+\n",
    "                              '_0.npy', allow_pickle=True)]\n",
    "for i in range(1, num_tracks):\n",
    "    print(i)\n",
    "    valid_tracks_arpc3 += [np.load(path_outputs+\n",
    "                           '/dataframes/'+\n",
    "                           name_secondary_structures+\n",
    "                           '_'+\n",
    "                           str(i)+\n",
    "                           '.npy', allow_pickle=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valid_tracks_arpc3 = merge_tools.merge_experiments(valid_tracks_arpc3,[list(range(len(track_set))) for track_set in valid_tracks_arpc3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all valid tracks ap2/dnm2 tracks from arpc3 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "merged_all_valid_tracks = np.load(path_outputs+\n",
    "                              '/dataframes/'+\n",
    "                              name_tracks+\n",
    "                              '_0.npy', allow_pickle=True)\n",
    "for i in range(1, num_tracks):\n",
    "    print(i)\n",
    "    merged_all_valid_tracks = np.concatenate((merged_all_valid_tracks,\n",
    "                                             np.load(path_outputs+\n",
    "                                             '/dataframes/'+\n",
    "                                             name_tracks+\n",
    "                                             '_'+\n",
    "                                             str(i)+\n",
    "                                             '.npy', allow_pickle=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_all_valid_tracks = np.load(unique_user_saved_outputs+'/dataframes/merged_all_valid_ada_tracks_0.npy', allow_pickle=True)\n",
    "\n",
    "# for i in range(1, num_arpc3_tracks):\n",
    "#     print(i)\n",
    "#     merged_all_valid_tracks = np.concatenate((merged_all_valid_tracks,\n",
    "#                                               np.load(unique_user_saved_outputs+'/dataframes/merged_all_valid_ada_tracks_'+str(i)+'.npy', allow_pickle=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95125,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_all_valid_tracks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort DNM2+ events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = analysis_metadata.item().get('number_of_clusters')\n",
    "\n",
    "num_gmm_clusters = number_of_clusters # optimal number of clusters of PCA data\n",
    "\n",
    "\n",
    "gmm_classes = []\n",
    "\n",
    "df = df_experiment\n",
    "\n",
    "for i in range(num_gmm_clusters):\n",
    "\n",
    "    gmm_classes.append(df[df['gmm_predictions']==i].index.values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dnm2positive = analysis_metadata.item().get('index_DNM2positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7859"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gmm_classes[index_dnm2positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_authentic_ccps_gmm = merged_all_valid_tracks[gmm_classes[index_dnm2positive]] #dnm2 positive events, mixed CCPS and hot-spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7859"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tracks_authentic_ccps_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate single-CCP events by experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_numbers = list(np.sort(list(set(df_experiment['experiment_number']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_numbers = [int(exp) for exp in experiment_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_best_fit = analysis_metadata.item().get('distance_best_fit')\n",
    "height_best_fit = analysis_metadata.item().get('height_best_fit')\n",
    "width_best_fit = analysis_metadata.item().get('width_best_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = signal.butter(4, 0.2, 'lp', fs=1, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "merged_all_valid_tracks_per_experiment = [] # each entry is a list for each experiment of tracks corresponding to predicted ccps \n",
    "\n",
    "non_peaked_dnm2_events_per_experiment = []\n",
    "\n",
    "for experiment_number in experiment_numbers: # only look at 3-color movies\n",
    "    print(experiment_number)\n",
    "    tracks_exp_idx = df[df['experiment_number']==experiment_number].index.values\n",
    "    tracks_exp = merged_all_valid_tracks[tracks_exp_idx]\n",
    "    \n",
    "    num_peaks_temp = []\n",
    "\n",
    "    for i in range(len(tracks_exp)):\n",
    "\n",
    "        raw_intensity = return_track_attributes.return_track_amplitude_no_buffer_channel(tracks_exp,i,1)\n",
    "\n",
    "        # add zeros to end to account for phase shift of near-track-end peaks\n",
    "        filtered_amplitude = list(list(signal.sosfilt(sos, raw_intensity)) + [0, 0, 0, 0, 0])\n",
    "\n",
    "        num_peaks_event = len(signal.find_peaks(filtered_amplitude, \n",
    "                                 distance=distance_best_fit, \n",
    "                                 height=height_best_fit,\n",
    "                                 width=width_best_fit)[0])\n",
    "\n",
    "        \n",
    "        num_peaks_temp.append(num_peaks_event)\n",
    "    \n",
    "    idx_nonpeaked_exp = np.where(np.array(num_peaks_temp)==0)[0]\n",
    "    \n",
    "    non_peaked_dnm2_events_per_experiment.append(tracks_exp[idx_nonpeaked_exp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # measure ap2 initiation to dnm2 peak lifetime, comparing 2 cell lines -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all CCPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ccps = merge_tools.merge_experiments(non_peaked_dnm2_events_per_experiment, [list(range(len(track_set))) for track_set in non_peaked_dnm2_events_per_experiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90858"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_ccps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload (or load) trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arpc3_wildtype_no-treatment_separate_arpc3_tracking'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_secondary_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "arpc3_trees = []\n",
    "\n",
    "string_index_matrix = name_secondary_structures + '_kdtree'\n",
    "\n",
    "string_tree = name_secondary_structures + '_kdtree'\n",
    "\n",
    "for i in range(0,num_tracks):\n",
    "    print(i)\n",
    "    name_tree = path_outputs+'/dataframes/'+string_tree+'_'+str(i)\n",
    "    with open(name_tree, 'rb') as f:\n",
    "        tree = pickle.load(f)\n",
    "        \n",
    "    index_matrix = np.load(path_outputs+\n",
    "                           '/dataframes/'+\n",
    "                           string_index_matrix+\n",
    "                           '_index_matrix_'+\n",
    "                           str(i)+\n",
    "                           '.npy', \n",
    "                           allow_pickle=True)\n",
    "\n",
    "    arpc3_trees.append([tree, index_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fit = analysis_metadata.item().get('distance_best_fit')\n",
    "height_fit = analysis_metadata.item().get('height_best_fit')\n",
    "width_fit = analysis_metadata.item().get('width_best_fit')\n",
    "\n",
    "best_fit_peak_params = [dist_fit,\n",
    "                        height_fit,\n",
    "                        width_fit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current experiment number: 8\n",
      "number of ap2 tracks: 5877\n",
      "number of arpc3 tracks: 17512\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.09258160237388724\n",
      "current experiment number: 9\n",
      "number of ap2 tracks: 7223\n",
      "number of arpc3 tracks: 16177\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.09330261642257692\n",
      "current experiment number: 10\n",
      "number of ap2 tracks: 8043\n",
      "number of arpc3 tracks: 15491\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.08924115661235872\n",
      "current experiment number: 11\n",
      "number of ap2 tracks: 7226\n",
      "number of arpc3 tracks: 17968\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.11826522101751459\n",
      "current experiment number: 12\n",
      "number of ap2 tracks: 7349\n",
      "number of arpc3 tracks: 18152\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.10679611650485436\n",
      "current experiment number: 13\n",
      "number of ap2 tracks: 7603\n",
      "number of arpc3 tracks: 17762\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.09157621158844213\n",
      "current experiment number: 14\n",
      "number of ap2 tracks: 6375\n",
      "number of arpc3 tracks: 17611\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.08953851810994669\n",
      "current experiment number: 15\n",
      "number of ap2 tracks: 6341\n",
      "number of arpc3 tracks: 15483\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.08331793829669315\n",
      "current experiment number: 16\n",
      "number of ap2 tracks: 7319\n",
      "number of arpc3 tracks: 14466\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.07743845434714865\n",
      "current experiment number: 17\n",
      "number of ap2 tracks: 7389\n",
      "number of arpc3 tracks: 15603\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.08569218870843001\n",
      "current experiment number: 18\n",
      "number of ap2 tracks: 7115\n",
      "number of arpc3 tracks: 13732\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.07112375533428165\n",
      "current experiment number: 19\n",
      "number of ap2 tracks: 7020\n",
      "number of arpc3 tracks: 14599\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.07781350482315112\n",
      "current experiment number: 20\n",
      "number of ap2 tracks: 5978\n",
      "number of arpc3 tracks: 15194\n",
      "iterating through tracks in experiment\n",
      "fraction of events with arpc3 0.08129619101762366\n"
     ]
    }
   ],
   "source": [
    "distance_query = 2 # pixel search radius for associating ap2 and arpc3 from separate tracking\n",
    "\n",
    "# arpc3 positive events, padded in non-overlapping frames\n",
    "ch0_vectors_arpc3_positive = [] # amplitudes #\n",
    "ch1_vectors_arpc3_positive = [] #\n",
    "ch2_vectors_arpc3_positive = [] #\n",
    "channel_0_1_separations_arpc3_positive = [] # distance in microns between ap2 and dnm2\n",
    "channel_0_2_separations_arpc3_positive = [] # distance in microns between ap2 and arpc3\n",
    "channel_1_2_separations_arpc3_positive = []\n",
    "final_separations_ap2arpc3_arpc3_positive = [] # ap2 and arpc3 final separation in last overlapping frame of ap2 and arpc3\n",
    "initial_separations_ap2arpc3_arpc3_positive = [] # ap2 and arpc3 initial separation in first overlapping frame of ap2 and arpc3\n",
    "ap2_arpc3_separation_at_dnm2_peak_arpc3_positive = [] # ap2 and arpc3 separation at peak of dnm2 signal\n",
    "ap2_arpc3_separation_at_arpc3_peak_arpc3_positive = []\n",
    "ap2_arpc3_separation_at_ap2_peak_arpc3_positive = []\n",
    "ap2_lifetime_arpc3_positive = [] # ap2 lifetime\n",
    "arpc3_lifetime_arpc3_positive = []\n",
    "max_separation_ap2_arpc3_arpc3_positive = [] # maximum separation between ap2 and arpc3\n",
    "max_separation_ap2_dnm2_arpc3_positive = []\n",
    "max_separation_dnm2_arpc3_arpc3_positive = []\n",
    "num_frames_associated_arpc3_positive = [] # number of frames shared between ap2 and arpc3 in movie that are below the query radius in KDTree search\n",
    "time_ap2_appearance_to_dnm2_peak_arpc3_positive = []\n",
    "maximum_ap2_intensity_arpc3_positive = []\n",
    "maximum_dnm2_intensity_arpc3_positive = []\n",
    "maximum_arpc3_intensity_arpc3_positive = []\n",
    "pval_arpc3_ccps_arpc3_positive = []\n",
    "time_arpc3_appearance_to_dnm2_peak_arpc3_positive = []\n",
    "fraction_arpc3_positive = []\n",
    "ccps_arpc3_positive = []\n",
    "average_ap2_movement_before_dnm2_peak_arpc3_positive = []\n",
    "average_ap2_movement_after_dnm2_peak_arpc3_positive = []\n",
    "\n",
    "ap2_arpc3_separation_average_arpc3_positive = []\n",
    "experiment_number_arpc3_positive = []\n",
    "dnm2_arpc3_peak_time_difference_arpc3_positive = []\n",
    "\n",
    "\n",
    "# arpc3 negative events\n",
    "ch0_vectors_arpc3_negative = []\n",
    "ch1_vectors_arpc3_negative = []\n",
    "channel_0_1_separations_arpc3_negative = []\n",
    "ccps_arpc3_negative = []\n",
    "time_ap2_appearance_to_dnm2_peak_arpc3_negative = []\n",
    "ap2_lifetime_arpc3_negative = []\n",
    "experiment_number_arpc3_negative = []\n",
    "average_ap2_movement_before_dnm2_peak_arpc3_negative = []\n",
    "average_ap2_movement_after_dnm2_peak_arpc3_negative = []\n",
    "\n",
    "\n",
    "num_frames_associated = []\n",
    "\n",
    "\n",
    "significant_arpc3_at_dnm2_peak_arpc3_positive = []\n",
    "\n",
    "num_no_neighbors = 0\n",
    "\n",
    "for exp_num, experiment_number in enumerate(experiment_numbers):  # iterate over all experiments\n",
    "\n",
    "    \n",
    "    num_with_mode = 0 # count number of events with and without arpc3\n",
    "    num_without_mode = 0    \n",
    "    num_no_neighbors=0\n",
    "    print('current experiment number: ' + str(experiment_number))\n",
    "    ap2dmn2_tracks_in_experiment = non_peaked_dnm2_events_per_experiment[exp_num] # filtered tracks\n",
    "    print('number of ap2 tracks: ' + str(len(ap2dmn2_tracks_in_experiment)))\n",
    "    arpc3_experiment=valid_tracks_arpc3[exp_num] # cat 1 and 2 arpc3 events in experiment\n",
    "    print('number of arpc3 tracks: ' + str(len(arpc3_experiment)))\n",
    "\n",
    "    \n",
    "    # select a tree for each frame containing all events in each frame\n",
    "    kd_tree_arpc3_experiment, vals_tree = arpc3_trees[exp_num]\n",
    "    \n",
    "    print('iterating through tracks in experiment')\n",
    "    \n",
    "    for track_num in range(len(ap2dmn2_tracks_in_experiment)): # iterate through all ap2 tracks in experiment\n",
    "\n",
    "        \n",
    "        frames_in_track_first_channel = list(return_track_attributes.return_frames_in_track_no_buffer(ap2dmn2_tracks_in_experiment, track_num)-1) # frames of ap2 and dnm2\n",
    "        ch0_x = return_track_attributes.return_puncta_x_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 0) # positions of ap2 and dnm2\n",
    "        ch0_y = return_track_attributes.return_puncta_y_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 0)\n",
    "        ch1_x = return_track_attributes.return_puncta_x_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 1)\n",
    "        ch1_y = return_track_attributes.return_puncta_y_position_no_buffer_one_channel(ap2dmn2_tracks_in_experiment, track_num, 1)\n",
    "        ap2_int = return_track_attributes.return_track_amplitude_no_buffer_channel(ap2dmn2_tracks_in_experiment, track_num, 0) # ap2 and dnm2 intensities\n",
    "        dnm2_int = return_track_attributes.return_track_amplitude_no_buffer_channel(ap2dmn2_tracks_in_experiment, track_num, 1)\n",
    "        \n",
    "#         filtered_dnm2_signal = list(list(signal.sosfilt(sos, dnm2_int)) + [0, 0, 0, 0, 0])\n",
    "    \n",
    "#         dnm2_peak = signal.find_peaks(filtered_dnm2_signal, \n",
    "#                                       distance=best_fit_peak_params[0], \n",
    "#                                       height=best_fit_peak_params[1],\n",
    "#                                       width=best_fit_peak_params[2])[0][0]\n",
    "        \n",
    "#         frame_dnm2_peak = frames_in_track_first_channel[dnm2_peak] # the movie frame (indexed starting from 0) that dnm2 peaks     \n",
    "        candidate_arpc3_neighbors = [] # indices of arpc3 events that take place near ap2\n",
    "        no_neighbors=True # no neighbors found yet\n",
    "        \n",
    "        # search for candidate arpc3 neighbors in each ap2 track's frame\n",
    "        for frame in frames_in_track_first_channel:\n",
    "            \n",
    "            frame_ch0 = frames_in_track_first_channel.index(frame)\n",
    "            # frame's tree\n",
    "            current_tree = kd_tree_arpc3_experiment[frame]\n",
    "            \n",
    "            # ap2 fitted position at current frame\n",
    "            current_ap2_position = np.array([ch0_x[frame_ch0], ch0_y[frame_ch0]]).reshape(1, -1)\n",
    "            \n",
    "            # indices of arpc3 events within the query radius\n",
    "            ind = current_tree.query_radius(current_ap2_position,\n",
    "                                            r=distance_query)\n",
    "\n",
    "            if len(ind[0])>0:\n",
    "                no_neighbors = False # if there is a neighbor\n",
    "                \n",
    "            # check if each arpc3 neighbor originated before or after the ap2 event\n",
    "            for candidate in ind[0]:\n",
    "\n",
    "                candidate_index = int(vals_tree[frame][candidate][0]) # get the index of the arpc3 event\n",
    "                \n",
    "                frames_in_track_candidate_neighbor = list(return_track_attributes.return_frames_in_track_no_buffer(arpc3_experiment, candidate_index)-1)\n",
    "                \n",
    "                # consider the arpc3 event if it originated after the ap2 event\n",
    "                if frames_in_track_candidate_neighbor[0]>frames_in_track_first_channel[0]:\n",
    "\n",
    "                    candidate_arpc3_neighbors.append(candidate_index)\n",
    "        \n",
    "            \n",
    "        if no_neighbors==True: # if there are absolutely no neighbors present, the CCP is arpc3 negative\n",
    "            \n",
    "            num_no_neighbors+=1\n",
    "            \n",
    "        # get mode(s) of candidates\n",
    "        mode=stats.mode(candidate_arpc3_neighbors)\n",
    "        \n",
    "        # if there is a unique candidate:\n",
    "        if mode[0].size == 1:\n",
    "\n",
    "            num_frames_associated.append(mode[1][0])\n",
    "            \n",
    "            num_with_mode+=1 # count this track as arpc3 positive\n",
    "\n",
    "            pval_arpc3_detection = []\n",
    "            \n",
    "        \n",
    "            associated_track_second_channel = mode[0][0] # index of arpc3 track associated with current ap2 track\n",
    "            \n",
    "            frames_in_track_second_channel = list(return_track_attributes.return_frames_in_track_no_buffer(arpc3_experiment, associated_track_second_channel)-1) # frames of arpc3 track\n",
    "            \n",
    "            frames_intersection = list(set(frames_in_track_first_channel) & set(frames_in_track_second_channel)) # find all frames ap2 and arpc3 overlap during movie\n",
    "            frames_intersection.sort() # sort the frames in ascending order\n",
    "\n",
    "            # amplitudes of all channels\n",
    "            ch0_amplitudes = ap2_int # ap2, dnm2, arpc3 intensities\n",
    "            ch1_amplitudes = dnm2_int\n",
    "            ch2_amplitudes = return_track_attributes.return_track_amplitude_no_buffer_channel(arpc3_experiment, associated_track_second_channel, 0)\n",
    "\n",
    "            # position of arpc3\n",
    "            ch2_x = return_track_attributes.return_puncta_x_position_no_buffer_one_channel(arpc3_experiment, associated_track_second_channel, 0)\n",
    "            ch2_y = return_track_attributes.return_puncta_y_position_no_buffer_one_channel(arpc3_experiment, associated_track_second_channel, 0)\n",
    "\n",
    "            # correct intensities and positions for missing frames where ap2 and arpc3 are non-overlapping\n",
    "            new_ch0_vector = []\n",
    "            new_ch1_vector = []\n",
    "            new_ch2_vector = []\n",
    "            new_ch0_x = []\n",
    "            new_ch0_y = []\n",
    "            new_ch1_x = []\n",
    "            new_ch1_y = []\n",
    "            new_ch2_x = []\n",
    "            new_ch2_y = []\n",
    "            \n",
    "            # first/last frame either ap2 or arpc3 shows up\n",
    "            min_frame = np.nanmin([np.nanmin(frames_in_track_first_channel),np.nanmin(frames_in_track_second_channel)]) #nan to account for gaps\n",
    "            max_frame = np.nanmax([np.nanmax(frames_in_track_first_channel),np.nanmax(frames_in_track_second_channel)])\n",
    "\n",
    "            # all frames shared between ap2 and arpc3\n",
    "            frames_all = [i for i in range(int(min_frame),int(max_frame)+1)]\n",
    "\n",
    "            channel_0_2_separation_track = [] # ap2 and arpc3 separation\n",
    "            channel_0_2_angle_track = [] # ap2 and arpc3 angle \n",
    "            channel_0_1_separation_track = [] # ap2 and dnm2 separation\n",
    "            channel_1_2_separation_track = []\n",
    "\n",
    "            for frame in frames_all: # iterate over all frames\n",
    "\n",
    "                # if frames of ap2 and arpc3 are non-overlapping, do not measure their separation\n",
    "                if (frame in frames_in_track_first_channel and frame not in frames_in_track_second_channel) or (frame in frames_in_track_second_channel and frame not in frames_in_track_first_channel):\n",
    "                    channel_0_2_separation_track.append(0)\n",
    "                    channel_0_2_angle_track.append(0)\n",
    "                    channel_1_2_separation_track.append(0)\n",
    "                # if only ap2 is present\n",
    "                if frame in frames_in_track_first_channel and frame not in frames_in_track_second_channel:\n",
    "                    \n",
    "                    channel_0_index = frames_in_track_first_channel.index(frame) # get relative index of ap2 in this frame \n",
    "\n",
    "                    new_ch0_vector.append(ch0_amplitudes[channel_0_index]) # add ap2 and dnm2 amplitudes\n",
    "                    new_ch1_vector.append(ch1_amplitudes[channel_0_index]) \n",
    "                    new_ch0_x.append(ch0_x[channel_0_index]) # ap2 and dnm2 positions\n",
    "                    new_ch0_y.append(ch0_y[channel_0_index])\n",
    "                    new_ch1_x.append(ch1_x[channel_0_index])\n",
    "                    new_ch1_y.append(ch1_y[channel_0_index])\n",
    "\n",
    "                    new_ch2_vector.append(0) # no arpc3\n",
    "                    new_ch2_x.append(0) # arpc3 position off grid\n",
    "                    new_ch2_y.append(0)\n",
    "                    pval_arpc3_detection.append(np.NaN)\n",
    "                    \n",
    "                    channel_0_1_separation_track.append(np.sqrt((0.108*(ch0_x[channel_0_index]-ch1_x[channel_0_index]))**2 + (0.108*(ch0_y[channel_0_index]-ch1_y[channel_0_index]))**2)) # ap2-dnm2 separation\n",
    "\n",
    "                # if only arpc3 is present\n",
    "                elif frame in frames_in_track_second_channel and frame not in frames_in_track_first_channel: \n",
    "\n",
    "                    channel_2_index = frames_in_track_second_channel.index(frame) # get relative index of arpc3 in this frame \n",
    "\n",
    "                    new_ch2_vector.append(ch2_amplitudes[channel_2_index]) # add arpc3 amplitudes and positions\n",
    "                    new_ch2_x.append(ch2_x[channel_2_index]) \n",
    "                    new_ch2_y.append(ch2_y[channel_2_index])\n",
    "                    \n",
    "                    new_ch0_vector.append(0) # no ap2 or dnm2\n",
    "                    new_ch1_vector.append(0)    \n",
    "                    new_ch0_x.append(0) # ap2 and dnm2 position off grid\n",
    "                    new_ch0_y.append(0)\n",
    "                    new_ch1_x.append(0)\n",
    "                    new_ch1_y.append(0)\n",
    "           \n",
    "                    channel_0_1_separation_track.append(0) # no separation between ap2 and dnm2 \n",
    "                    \n",
    "                    pval_arpc3_detection.append(return_track_attributes.return_pvals_detection_no_buffer(arpc3_experiment, associated_track_second_channel, 0)[channel_2_index])\n",
    "                \n",
    "                # if both ap2 and arpc3 in frame\n",
    "                elif frame in frames_in_track_first_channel and frame in frames_in_track_second_channel:  \n",
    "\n",
    "                    channel_0_index = frames_in_track_first_channel.index(frame) # get relative indices\n",
    "                    channel_2_index = frames_in_track_second_channel.index(frame)\n",
    "\n",
    "                    new_ch0_vector.append(ch0_amplitudes[channel_0_index]) # add amplitudes and positionsfor all channels\n",
    "                    new_ch1_vector.append(ch1_amplitudes[channel_0_index])\n",
    "                    new_ch2_vector.append(ch2_amplitudes[channel_2_index])\n",
    "                    new_ch0_x.append(ch0_x[channel_0_index]) # ap2 and dnm2 positions\n",
    "                    new_ch0_y.append(ch0_y[channel_0_index])\n",
    "                    new_ch1_x.append(ch1_x[channel_0_index])\n",
    "                    new_ch1_y.append(ch1_y[channel_0_index])\n",
    "                    new_ch2_x.append(ch2_x[channel_2_index]) \n",
    "                    new_ch2_y.append(ch2_y[channel_2_index])\n",
    "\n",
    "                    channel_0_1_separation_track.append(np.sqrt((0.108*(ch0_x[channel_0_index]-ch1_x[channel_0_index]))**2 + (0.108*(ch0_y[channel_0_index]-ch1_y[channel_0_index]))**2)) # ap2-dnm2 separation\n",
    "                    \n",
    "                    # ap2 and arpc3 separation\n",
    "                    channel_0_2_separation_track.append(np.sqrt((0.108*(ch0_x[channel_0_index]-ch2_x[channel_2_index]))**2 + (0.108*(ch0_y[channel_0_index]-ch2_y[channel_2_index]))**2))\n",
    "#                     channel_0_2_angle_track.append(angle_between((0,0),((ch0_x[channel_0_index]-ch2_x[channel_2_index]),(ch0_y[channel_0_index]-ch2_y[channel_2_index]))))              \n",
    "                    channel_1_2_separation_track.append(np.sqrt((0.108*(ch1_x[channel_0_index]-ch2_x[channel_2_index]))**2 + (0.108*(ch1_y[channel_0_index]-ch2_y[channel_2_index]))**2))\n",
    "\n",
    "                    pval_arpc3_detection.append(return_track_attributes.return_pvals_detection_no_buffer(arpc3_experiment,associated_track_second_channel,0)[channel_2_index])\n",
    " \n",
    "            filtered_dnm2_signal = list(list(signal.sosfilt(sos, dnm2_int)) + [0, 0, 0, 0, 0])\n",
    "    \n",
    "#             dnm2_peak = signal.find_peaks(filtered_dnm2_signal, \n",
    "#                                           distance=best_fit_peak_params[0], \n",
    "#                                           height=best_fit_peak_params[1],\n",
    "#                                           width=best_fit_peak_params[2])[0][0]\n",
    "        \n",
    "#             if pval_arpc3_detection[dnm2_peak]<0.01 and pval_arpc3_detection[dnm2_peak]!=np.NaN:\n",
    "            \n",
    "#                 significant_arpc3_at_dnm2_peak_arpc3_positive.append(1)\n",
    "            \n",
    "#             else:\n",
    "                \n",
    "#                 significant_arpc3_at_dnm2_peak_arpc3_positive.append(0)\n",
    "    \n",
    "            ccps_arpc3_positive.append(ap2dmn2_tracks_in_experiment[track_num])\n",
    "            ap2_lifetime_arpc3_positive.append(len(frames_in_track_first_channel))\n",
    "            arpc3_lifetime_arpc3_positive.append(len(frames_in_track_second_channel))\n",
    "            # measure ap2 and arpc3 separation at dnm2 peak\n",
    "\n",
    "#             ap2_arpc3_separation_at_dnm2_peak_arpc3_positive.append(channel_0_2_separation_track[dnm2_peak])\n",
    "            ap2_arpc3_separation_at_arpc3_peak_arpc3_positive.append(channel_0_2_separation_track[np.nanargmax(new_ch2_vector)])\n",
    "            ap2_arpc3_separation_at_ap2_peak_arpc3_positive.append(channel_0_2_separation_track[np.nanargmax(new_ch0_vector)])\n",
    "            ap2_arpc3_separation_average_arpc3_positive.append(np.nanmean(channel_0_2_separation_track))\n",
    "            # store measurements\n",
    "            ch0_vectors_arpc3_positive.append(new_ch0_vector)\n",
    "            ch1_vectors_arpc3_positive.append(new_ch1_vector)\n",
    "            ch2_vectors_arpc3_positive.append(new_ch2_vector)\n",
    "#             print(new_ch2_vector)\n",
    "            channel_0_2_separations_arpc3_positive.append(channel_0_2_separation_track)\n",
    "            channel_0_1_separations_arpc3_positive.append(channel_0_1_separation_track)  \n",
    "            channel_1_2_separations_arpc3_positive.append(channel_1_2_separation_track)  \n",
    "            channel_0_2_separation_track = np.array(channel_0_2_separation_track)\n",
    "            channel_0_1_separation_track = np.array(channel_0_1_separation_track)\n",
    "            channel_1_2_separation_track = np.array(channel_1_2_separation_track)\n",
    "            final_separations_ap2arpc3_arpc3_positive.append(channel_0_2_separation_track[~np.isnan(channel_0_2_separation_track)][-1])      \n",
    "            initial_separations_ap2arpc3_arpc3_positive.append(channel_0_2_separation_track[~np.isnan(channel_0_2_separation_track)][0])   \n",
    "            max_separation_ap2_arpc3_arpc3_positive.append(np.nanmax(channel_0_2_separation_track))\n",
    "            max_separation_ap2_dnm2_arpc3_positive.append(np.nanmax(channel_0_1_separation_track))\n",
    "            max_separation_dnm2_arpc3_arpc3_positive.append(np.nanmax(channel_1_2_separation_track))\n",
    "            num_frames_associated_arpc3_positive.append(mode[1][0])\n",
    "            pval_arpc3_ccps_arpc3_positive.append(pval_arpc3_detection)\n",
    "            maximum_ap2_intensity_arpc3_positive.append(np.nanmax(new_ch0_vector))\n",
    "            maximum_dnm2_intensity_arpc3_positive.append(np.nanmax(new_ch1_vector))\n",
    "            maximum_arpc3_intensity_arpc3_positive.append(np.nanmax(new_ch2_vector))      \n",
    "#             time_ap2_appearance_to_dnm2_peak_arpc3_positive.append(dnm2_peak)\n",
    "#             time_arpc3_appearance_to_dnm2_peak_arpc3_positive.append(int(frames_in_track_first_channel[dnm2_peak]) - int(frames_in_track_second_channel[0]))\n",
    "            experiment_number_arpc3_positive.append(exp_num)\n",
    "            \n",
    "            dnm2_arpc3_peak_time_difference_arpc3_positive.append(np.nanargmax(ch1_amplitudes)-np.nanargmax(ch2_amplitudes))\n",
    "            \n",
    "            # concatenate all track positions and amplitudes\n",
    "            track_x_positions = [new_ch0_x, new_ch1_x, new_ch2_x]\n",
    "            track_y_positions = [new_ch0_y, new_ch1_y, new_ch2_y]\n",
    "            channel_intensity_vectors = [new_ch0_vector, new_ch1_vector, new_ch2_vector]   \n",
    "             \n",
    "#             ap2_x_positions = new_ch0_x\n",
    "#             ap2_y_positions = new_ch0_y     \n",
    "            \n",
    "#             num_before=5\n",
    "#             ap2movement = []\n",
    "#             for dnm2_index in range(dnm2_peak-num_before,dnm2_peak):\n",
    "\n",
    "#                 try: \n",
    "                    \n",
    "#                     if ap2_x_positions[dnm2_index] != 0 and ap2_x_positions[dnm2_index+1] != 0:\n",
    "                        \n",
    "#                         ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "#                         ap2movement.append(ap2temp)\n",
    "                        \n",
    "#                     else:\n",
    "                        \n",
    "#                         ap2movement.append(np.NaN)\n",
    "\n",
    "#                 except Exception:\n",
    "\n",
    "#                     ap2movement.append(np.NaN)\n",
    "\n",
    "#             average_ap2_movement_before_dnm2_peak_arpc3_positive.append(np.nanmean(ap2movement))            \n",
    "\n",
    "#             num_after=5\n",
    "#             ap2movement = []\n",
    "#             for dnm2_index in range(dnm2_peak,dnm2_peak+num_after):\n",
    "\n",
    "#                 try: \n",
    "                    \n",
    "#                     if ap2_x_positions[dnm2_index] != 0 and ap2_x_positions[dnm2_index+1] != 0:\n",
    "                        \n",
    "#                         ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "#                         ap2movement.append(ap2temp)\n",
    "                        \n",
    "#                     else:\n",
    "                        \n",
    "#                         ap2movement.append(np.NaN)\n",
    "\n",
    "#                 except Exception:\n",
    "\n",
    "#                     ap2movement.append(np.NaN)\n",
    "\n",
    "#             average_ap2_movement_after_dnm2_peak_arpc3_positive.append(np.nanmean(ap2movement)) \n",
    "            \n",
    "        elif no_neighbors==True: # if there is no mode then the event is arpc3 negative\n",
    "\n",
    "            num_without_mode += 1 \n",
    "            experiment_number_arpc3_negative.append(exp_num)\n",
    "            ccps_arpc3_negative.append(ap2dmn2_tracks_in_experiment[track_num])\n",
    "            ap2_lifetime_arpc3_negative.append(len(ap2_int))\n",
    "\n",
    "            ch0_vectors_arpc3_negative.append(ap2_int)\n",
    "            ch1_vectors_arpc3_negative.append(dnm2_int)\n",
    "\n",
    "            filtered_dnm2_signal = list(list(signal.sosfilt(sos, dnm2_int)) + [0, 0, 0, 0, 0])\n",
    "    \n",
    "#             dnm2_peak = signal.find_peaks(filtered_dnm2_signal, \n",
    "#                                           distance=best_fit_peak_params[0], \n",
    "#                                           height=best_fit_peak_params[1],\n",
    "#                                           width=best_fit_peak_params[2])[0][0]\n",
    "            \n",
    "#             time_ap2_appearance_to_dnm2_peak_arpc3_negative.append(dnm2_peak)\n",
    "            \n",
    "                        \n",
    "            channel_0_1_separation_track = []\n",
    "            \n",
    "            for frame in range(len(ch0_x)):\n",
    "                \n",
    "                channel_0_1_separation_track.append(np.sqrt((0.108*(ch0_x[frame]-ch1_x[frame]))**2 + (0.108*(ch0_y[frame]-ch1_y[frame]))**2)) # ap2-dnm2 separation\n",
    "\n",
    "            channel_0_1_separations_arpc3_negative.append(channel_0_1_separation_track)\n",
    "         \n",
    "            ap2_x_positions = ch0_x\n",
    "            ap2_y_positions = ch0_y     \n",
    "        \n",
    "            num_before=5\n",
    "            ap2movement = []\n",
    "#             for dnm2_index in range(dnm2_peak-num_before,dnm2_peak):\n",
    "\n",
    "#                 try: \n",
    "\n",
    "#                     ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "#                     ap2movement.append(ap2temp)\n",
    "\n",
    "#                 except Exception:\n",
    "\n",
    "#                     ap2movement.append(np.NaN)\n",
    "\n",
    "#             average_ap2_movement_before_dnm2_peak_arpc3_negative.append(np.nanmean(ap2movement))            \n",
    "\n",
    "#             num_after=5\n",
    "#             ap2movement = []\n",
    "#             for dnm2_index in range(dnm2_peak,dnm2_peak+num_after):\n",
    "\n",
    "#                 try: \n",
    "\n",
    "#                     ap2temp = np.sqrt((0.108*(ap2_x_positions[dnm2_index+1]-ap2_x_positions[dnm2_index]))**2 + (0.108*(ap2_y_positions[dnm2_index+1]-ap2_y_positions[dnm2_index]))**2)\n",
    "\n",
    "#                     ap2movement.append(ap2temp)\n",
    "\n",
    "#                 except Exception:\n",
    "\n",
    "#                     ap2movement.append(np.NaN)\n",
    "\n",
    "#             average_ap2_movement_after_dnm2_peak_arpc3_negative.append(np.nanmean(ap2movement))             \n",
    "          \n",
    "    print('fraction of events with arpc3', str(num_with_mode/(num_with_mode+num_no_neighbors)))\n",
    "    fraction_arpc3_positive.append(num_with_mode/(num_with_mode+num_no_neighbors))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09258160237388724,\n",
       " 0.09330261642257692,\n",
       " 0.08924115661235872,\n",
       " 0.11826522101751459,\n",
       " 0.10679611650485436,\n",
       " 0.09157621158844213,\n",
       " 0.08953851810994669,\n",
       " 0.08331793829669315,\n",
       " 0.07743845434714865,\n",
       " 0.08569218870843001,\n",
       " 0.07112375533428165,\n",
       " 0.07781350482315112,\n",
       " 0.08129619101762366]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraction_arpc3_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_to_save = ['ch0_vectors_arpc3_positive',\n",
    "                  'ch1_vectors_arpc3_positive',\n",
    "                  'ch2_vectors_arpc3_positive',\n",
    "                  'channel_0_1_separations_arpc3_positive',\n",
    "                  'channel_0_2_separations_arpc3_positive',\n",
    "                  'channel_1_2_separations_arpc3_positive',\n",
    "                  'ch0_vectors_arpc3_negative',\n",
    "                  'ch1_vectors_arpc3_negative',\n",
    "                  'channel_0_1_separations_arpc3_negative']\n",
    "\n",
    "merged_results = {}\n",
    "for array in arrays_to_save:\n",
    "    \n",
    "    merged_results[array] = locals()[array]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6963, 71257)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ccps_arpc3_positive), len(ccps_arpc3_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6963, 0, 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_frames_associated_arpc3_positive), len(ap2_arpc3_separation_at_dnm2_peak_arpc3_positive), len(significant_arpc3_at_dnm2_peak_arpc3_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_outputs+'/dataframes/'+experiment+'_merged_ccp_attributes_non_peaked', 'wb') as f:\n",
    "    pickle.dump(merged_results, f)   \n",
    "    \n",
    "np.save(path_outputs+'/dataframes/'+experiment+'_merged_arpc3_negative_ccps_non_peaked', ccps_arpc3_negative)\n",
    "    \n",
    "np.save(path_outputs+'/dataframes/'+experiment+'_merged_arpc3_positive_ccps_non_peaked', ccps_arpc3_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_outputs+'/dataframes/'+experiment+'_ap2_lifetime_arpc3_positive_non_peaked', ap2_lifetime_arpc3_positive)\n",
    "np.save(path_outputs+'/dataframes/'+experiment+'_ap2_lifetime_arpc3_negative_non_peaked', ap2_lifetime_arpc3_negative)\n",
    "np.save(path_outputs+'/dataframes/'+experiment+'_arpc3_lifetime_arpc3_positive_non_peaked', arpc3_lifetime_arpc3_positive)\n",
    "np.save(path_outputs+'/dataframes/'+experiment+'_fraction_arpc3_positive_non_peaked', fraction_arpc3_positive)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
